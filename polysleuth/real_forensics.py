"""
PolySleuth - çœŸå®é“¾ä¸Šæ•°æ®å–è¯åˆ†æå™¨

ä½¿ç”¨ Chainstack Polygon èŠ‚ç‚¹è·å–çœŸå®çš„é“¾ä¸Šäº¤æ˜“æ•°æ®
è¿›è¡Œåˆ·é‡æ£€æµ‹å’Œå¸‚åœºå¥åº·åº¦åˆ†æ

æ‰€æœ‰æ•°æ®å‡ä¸ºçœŸå®é“¾ä¸Šæ•°æ®ï¼Œæ— æ¨¡æ‹Ÿæ•°æ®
"""

import os
import json
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from collections import defaultdict
from decimal import Decimal
import logging

from dotenv import load_dotenv
from web3 import Web3
from web3.middleware import ExtraDataToPOAMiddleware
import requests

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================================================
# é…ç½®
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
POLYGON_RPC_URL = os.getenv('POLYGON_RPC_URL', 'https://polygon-rpc.com')
CTF_EXCHANGE = os.getenv('CTF_EXCHANGE_ADDRESS', '0x4bFb41d5B3570DeFd03C39a9A4D8dE6Bd8B8982E')
NEG_RISK_EXCHANGE = os.getenv('NEG_RISK_EXCHANGE_ADDRESS', '0xC5d563A36AE78145C45a50134d48A1215220f80a')
CONDITIONAL_TOKENS = os.getenv('CONDITIONAL_TOKENS_ADDRESS', '0x4D97DCd97eC945f40cF65F87097ACe5EA0476045')
GAMMA_API_URL = os.getenv('GAMMA_API_URL', 'https://gamma-api.polymarket.com')

# äº‹ä»¶ç­¾å (keccak256 å“ˆå¸Œ)
ORDER_FILLED_TOPIC = Web3.keccak(text="OrderFilled(bytes32,address,address,uint256,uint256,uint256,uint256,uint256)").hex()
POSITION_SPLIT_TOPIC = Web3.keccak(text="PositionSplit(address,address,bytes32,bytes32,uint256[],uint256)").hex()
POSITIONS_MERGE_TOPIC = Web3.keccak(text="PositionsMerge(address,address,bytes32,bytes32,uint256[],uint256)").hex()


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class RealTrade:
    """çœŸå®é“¾ä¸Šäº¤æ˜“"""
    tx_hash: str
    block_number: int
    log_index: int
    timestamp: datetime
    contract: str
    
    order_hash: str
    maker: str
    taker: str
    maker_asset_id: int
    taker_asset_id: int
    maker_amount: int
    taker_amount: int
    fee: int
    
    # è®¡ç®—å­—æ®µ
    side: str = ""
    token_id: str = ""
    price: float = 0.0
    size: float = 0.0
    
    # å–è¯æ ‡è®°
    is_wash: bool = False
    wash_type: str = ""
    wash_confidence: float = 0.0
    
    def __post_init__(self):
        """è®¡ç®—äº¤æ˜“æ–¹å‘å’Œä»·æ ¼"""
        if self.maker_asset_id == 0:
            # Maker ç»™ USDCï¼ŒTaker ç»™ Token -> BUY
            self.side = "BUY"
            self.token_id = str(self.taker_asset_id)
            usdc_amount = self.maker_amount
            token_amount = self.taker_amount
        else:
            # Maker ç»™ Tokenï¼ŒTaker ç»™ USDC -> SELL
            self.side = "SELL"
            self.token_id = str(self.maker_asset_id)
            usdc_amount = self.taker_amount
            token_amount = self.maker_amount
        
        # è®¡ç®—ä»·æ ¼å’Œè§„æ¨¡ (USDC ç²¾åº¦ 1e6)
        if token_amount > 0:
            self.price = usdc_amount / token_amount
        self.size = token_amount / 1e6


@dataclass
class TransactionBundle:
    """
    äº¤æ˜“æ†ç»‘ - åŒä¸€ tx_hash å†…çš„æ‰€æœ‰äº‹ä»¶
    ç”¨äºåŸå­çº§åˆ·é‡æ£€æµ‹
    """
    tx_hash: str
    block_number: int
    timestamp: datetime
    
    trades: List[RealTrade] = field(default_factory=list)
    has_split: bool = False
    has_merge: bool = False
    split_addresses: set = field(default_factory=set)
    merge_addresses: set = field(default_factory=set)
    
    # åˆ†æç»“æœ
    is_atomic_wash: bool = False
    wash_confidence: float = 0.0
    total_volume: Decimal = Decimal(0)
    involved_addresses: set = field(default_factory=set)
    
    def analyze(self):
        """åˆ†æäº¤æ˜“æ†ç»‘ï¼Œæ£€æµ‹åŸå­çº§åˆ·é‡"""
        # æ”¶é›†æ‰€æœ‰åœ°å€
        trade_makers = set()
        trade_takers = set()
        
        for trade in self.trades:
            self.involved_addresses.add(trade.maker.lower())
            self.involved_addresses.add(trade.taker.lower())
            trade_makers.add(trade.maker.lower())
            trade_takers.add(trade.taker.lower())
            self.total_volume += Decimal(str(trade.size * trade.price))
        
        # åŸå­çº§åˆ·é‡æ£€æµ‹ï¼šSplit -> Trade -> Merge æ¨¡å¼
        if self.has_split and self.has_merge and self.trades:
            self.is_atomic_wash = True
            self.wash_confidence = 0.85
            
            # å¦‚æœ split å‘èµ·è€…å‚ä¸äº†äº¤æ˜“
            if self.split_addresses & (trade_makers | trade_takers):
                self.wash_confidence = 0.92
            
            # å¦‚æœ split å’Œ merge æ˜¯åŒä¸€åœ°å€
            if self.split_addresses & self.merge_addresses:
                self.wash_confidence = 0.98
            
            # æ ‡è®°æ‰€æœ‰äº¤æ˜“ä¸ºåˆ·é‡
            for trade in self.trades:
                trade.is_wash = True
                trade.wash_type = "ATOMIC"
                trade.wash_confidence = self.wash_confidence


@dataclass
class MarketHealth:
    """å¸‚åœºå¥åº·åº¦"""
    token_id: str
    
    total_volume: Decimal = Decimal(0)
    organic_volume: Decimal = Decimal(0)
    wash_volume: Decimal = Decimal(0)
    
    total_trades: int = 0
    wash_trades: int = 0
    
    unique_traders: set = field(default_factory=set)
    suspicious_addresses: set = field(default_factory=set)
    
    @property
    def wash_ratio(self) -> float:
        if self.total_volume == 0:
            return 0.0
        return float(self.wash_volume / self.total_volume)
    
    @property
    def health_score(self) -> int:
        score = 100
        # åˆ·é‡æ¯”ä¾‹æ‰£åˆ†
        score -= int(self.wash_ratio * 50)
        # äº¤æ˜“è€…æ•°é‡
        num_traders = len(self.unique_traders)
        if num_traders < 5:
            score -= 25
        elif num_traders < 20:
            score -= 15
        elif num_traders < 50:
            score -= 5
        # å¯ç–‘åœ°å€
        if len(self.suspicious_addresses) > 5:
            score -= 15
        return max(0, min(100, score))


# ============================================================================
# é“¾ä¸Šæ•°æ®è·å–å™¨
# ============================================================================

class OnChainForensics:
    """
    çœŸå®é“¾ä¸Šæ•°æ®å–è¯åˆ†æå™¨
    
    ä» Polygon é“¾ä¸Šè·å– Polymarket äº¤æ˜“æ•°æ®å¹¶è¿›è¡Œåˆ†æ
    """
    
    def __init__(self, rpc_url: str = None):
        self.rpc_url = rpc_url or POLYGON_RPC_URL
        self.w3 = None
        self._connect()
        
        # æ•°æ®å­˜å‚¨
        self.trades: List[RealTrade] = []
        self.bundles: List[TransactionBundle] = []
        self.market_health: Dict[str, MarketHealth] = {}
        self.alerts: List[Dict] = []
        
        # åŒºå—æ—¶é—´ç¼“å­˜
        self._block_timestamps: Dict[int, datetime] = {}
        
        # Token ID -> å¸‚åœºä¿¡æ¯æ˜ å°„
        self._token_to_market: Dict[str, Dict] = {}
        self._market_map_loaded = False
        
        # çŠ¶æ€
        self._running = False
        self._last_block = 0
        self._lock = threading.Lock()
    
    def _connect(self):
        """è¿æ¥åˆ° Polygon èŠ‚ç‚¹"""
        try:
            self.w3 = Web3(Web3.HTTPProvider(self.rpc_url))
            # Polygon æ˜¯ PoA é“¾ï¼Œéœ€è¦ä¸­é—´ä»¶
            self.w3.middleware_onion.inject(ExtraDataToPOAMiddleware, layer=0)
            
            if self.w3.is_connected():
                chain_id = self.w3.eth.chain_id
                block = self.w3.eth.block_number
                logger.info(f"âœ… å·²è¿æ¥åˆ° Polygon (Chain ID: {chain_id}, Block: {block})")
                logger.info(f"   RPC: {self.rpc_url[:50]}...")
            else:
                logger.error("âŒ æ— æ³•è¿æ¥åˆ° Polygon èŠ‚ç‚¹")
        except Exception as e:
            logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}")
            self.w3 = None
    
    def load_market_map(self, limit: int = 500):
        """
        åŠ è½½ Token ID -> å¸‚åœºåç§°æ˜ å°„
        
        Args:
            limit: è·å–çš„å¸‚åœºæ•°é‡ä¸Šé™
        """
        if self._market_map_loaded:
            return
        
        try:
            # å°è¯•ç›¸å¯¹å¯¼å…¥
            try:
                from polysleuth.data_fetcher import GammaAPIClient
            except ImportError:
                from data_fetcher import GammaAPIClient
            
            gamma = GammaAPIClient()
            self._token_to_market = gamma.build_token_to_market_map(limit=limit)
            self._market_map_loaded = True
            logger.info(f"âœ… å·²åŠ è½½ {len(self._token_to_market)} ä¸ªå¸‚åœºæ˜ å°„")
        except Exception as e:
            logger.warning(f"åŠ è½½å¸‚åœºæ˜ å°„å¤±è´¥: {e}")
            self._token_to_market = {}
    
    def get_market_name(self, token_id: str) -> str:
        """
        è·å– token_id å¯¹åº”çš„å¸‚åœºåç§°
        
        Args:
            token_id: Token ID
        
        Returns:
            å¸‚åœºåç§° + ç»“æœæ–¹å‘ï¼Œå¦‚ "Will Trump win? (YES)"
        """
        if not self._market_map_loaded:
            self.load_market_map()
        
        if token_id in self._token_to_market:
            info = self._token_to_market[token_id]
            question = info.get('question', 'Unknown')
            outcome = info.get('outcome', '')
            # æˆªæ–­è¿‡é•¿çš„é—®é¢˜
            if len(question) > 50:
                question = question[:47] + "..."
            return f"{question} ({outcome})" if outcome else question
        
        return f"Token {token_id[:16]}..."
    
    def get_market_info(self, token_id: str) -> Optional[Dict]:
        """è·å– token_id å¯¹åº”çš„å®Œæ•´å¸‚åœºä¿¡æ¯"""
        if not self._market_map_loaded:
            self.load_market_map()
        
        return self._token_to_market.get(token_id)
    
    def get_markets_summary(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ¶‰åŠå¸‚åœºçš„æ±‡æ€»ä¿¡æ¯
        æŒ‰ event/question èšåˆï¼Œé¿å… YES/NO é‡å¤æ˜¾ç¤º
        
        Returns:
            æŒ‰äº¤æ˜“é‡æ’åºçš„å¸‚åœºåˆ—è¡¨
        """
        # ç¡®ä¿å¸‚åœºæ˜ å°„å·²åŠ è½½
        if not self._market_map_loaded:
            self.load_market_map(limit=1000)
        
        # å°è¯•å¯¼å…¥ API å®¢æˆ·ç«¯ç”¨äºåŠ¨æ€è·å–
        try:
            try:
                from polysleuth.data_fetcher import GammaAPIClient
            except ImportError:
                from data_fetcher import GammaAPIClient
            gamma_api = GammaAPIClient()
        except:
            gamma_api = None
        
        # å…ˆæŒ‰ token_id ç»Ÿè®¡
        token_stats = defaultdict(lambda: {
            'token_id': '',
            'question': '',
            'outcome': '',
            'condition_id': '',
            'trade_count': 0,
            'volume': 0.0,
            'wash_count': 0,
            'unique_traders': set(),
        })
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„ token_ids
        unknown_tokens = set()
        
        for trade in self.trades:
            tid = trade.token_id
            stats = token_stats[tid]
            stats['token_id'] = tid
            stats['trade_count'] += 1
            stats['volume'] += trade.size * trade.price
            if trade.is_wash:
                stats['wash_count'] += 1
            stats['unique_traders'].add(trade.maker)
            stats['unique_traders'].add(trade.taker)
            
            # è·å–å¸‚åœºåç§°
            if not stats['question']:
                info = self.get_market_info(tid)
                if info:
                    stats['question'] = info.get('question', '')
                    stats['outcome'] = info.get('outcome', '')
                    stats['condition_id'] = info.get('condition_id', '')
                else:
                    unknown_tokens.add(tid)
        
        # åŠ¨æ€è·å–æœªçŸ¥ token çš„å¸‚åœºä¿¡æ¯
        if gamma_api and unknown_tokens:
            logger.info(f"ğŸ” åŠ¨æ€è·å– {len(unknown_tokens)} ä¸ªæœªçŸ¥å¸‚åœº...")
            for tid in list(unknown_tokens)[:50]:  # é™åˆ¶æœ€å¤šæŸ¥è¯¢ 50 ä¸ª
                try:
                    market = gamma_api.get_market_by_token_id(tid)
                    if market:
                        question = market.get('question', '')
                        tokens = market.get('tokens', [])
                        outcome = ''
                        for t in tokens:
                            if str(t.get('token_id', '')) == tid:
                                outcome = t.get('outcome', '').upper()
                                break
                        
                        if question:
                            token_stats[tid]['question'] = question
                            token_stats[tid]['outcome'] = outcome
                            # ç¼“å­˜åˆ°æ˜ å°„
                            self._token_to_market[tid] = {
                                'question': question,
                                'outcome': outcome,
                                'condition_id': market.get('conditionId', ''),
                            }
                except Exception as e:
                    pass
        
        # æŒ‰ question (event) åˆå¹¶ YES/NO
        event_stats = defaultdict(lambda: {
            'question': '',
            'token_ids': [],
            'trade_count': 0,
            'volume': 0.0,
            'wash_count': 0,
            'unique_traders': set(),
            'outcomes': [],
        })
        
        for tid, stats in token_stats.items():
            question = stats['question'] or f"Token {tid[:16]}..."
            event = event_stats[question]
            event['question'] = question
            event['token_ids'].append(tid)
            event['trade_count'] += stats['trade_count']
            event['volume'] += stats['volume']
            event['wash_count'] += stats['wash_count']
            event['unique_traders'].update(stats['unique_traders'])
            if stats['outcome']:
                event['outcomes'].append(stats['outcome'])
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        result = []
        for question, stats in event_stats.items():
            result.append({
                'question': question,
                'token_ids': stats['token_ids'],
                'trade_count': stats['trade_count'],
                'volume': stats['volume'],
                'wash_count': stats['wash_count'],
                'wash_ratio': stats['wash_count'] / stats['trade_count'] if stats['trade_count'] > 0 else 0,
                'unique_traders': len(stats['unique_traders']),
                'outcomes': list(set(stats['outcomes'])),
            })
        
        # æŒ‰äº¤æ˜“é‡é™åº
        result.sort(key=lambda x: x['volume'], reverse=True)
        return result
    
    def _get_block_timestamp(self, block_number: int) -> datetime:
        """è·å–åŒºå—æ—¶é—´ï¼ˆä½¿ç”¨ç¼“å­˜æˆ–ä¼°ç®—ï¼‰"""
        if block_number in self._block_timestamps:
            return self._block_timestamps[block_number]
        
        # ä½¿ç”¨ä¼°ç®—æ—¶é—´ï¼ˆPolygon çº¦ 2 ç§’ä¸€ä¸ªåŒºå—ï¼‰
        now = datetime.now()
        try:
            current_block = self.w3.eth.block_number
            seconds_ago = (current_block - block_number) * 2
            self._block_timestamps[block_number] = now - timedelta(seconds=seconds_ago)
        except:
            self._block_timestamps[block_number] = now
        
        return self._block_timestamps[block_number]
    
    def _prefetch_block_timestamps(self, block_numbers: List[int]):
        """æ‰¹é‡é¢„å–åŒºå—æ—¶é—´ï¼ˆåªè·å–é¦–å°¾åŒºå—ï¼Œå…¶ä½™ç”¨æ’å€¼ï¼‰"""
        unique_blocks = sorted(set(block_numbers) - set(self._block_timestamps.keys()))
        if not unique_blocks:
            return
        
        # åªè·å–é¦–å°¾ä¸¤ä¸ªåŒºå—çš„çœŸå®æ—¶é—´ï¼Œå…¶ä½™ç”¨æ’å€¼
        first_block = unique_blocks[0]
        last_block = unique_blocks[-1]
        
        logger.info(f"   è·å–é¦–å°¾åŒºå—æ—¶é—´æˆ³ ({first_block}, {last_block})...")
        
        try:
            # è·å–ç¬¬ä¸€ä¸ªåŒºå—æ—¶é—´
            block_data = self.w3.eth.get_block(first_block)
            first_time = datetime.fromtimestamp(block_data['timestamp'])
            self._block_timestamps[first_block] = first_time
            
            # è·å–æœ€åä¸€ä¸ªåŒºå—æ—¶é—´
            if first_block != last_block:
                block_data = self.w3.eth.get_block(last_block)
                last_time = datetime.fromtimestamp(block_data['timestamp'])
                self._block_timestamps[last_block] = last_time
            else:
                last_time = first_time
            
            # è®¡ç®—æ¯ä¸ªåŒºå—çš„å¹³å‡æ—¶é—´
            if last_block > first_block:
                total_seconds = (last_time - first_time).total_seconds()
                seconds_per_block = total_seconds / (last_block - first_block)
            else:
                seconds_per_block = 2.0  # Polygon å¹³å‡å€¼
            
            # å¯¹æ‰€æœ‰åŒºå—è¿›è¡Œæ’å€¼
            for block_num in unique_blocks:
                if block_num not in self._block_timestamps:
                    offset = block_num - first_block
                    self._block_timestamps[block_num] = first_time + timedelta(seconds=offset * seconds_per_block)
            
            logger.info(f"   âœ… å·²ä¸º {len(unique_blocks)} ä¸ªåŒºå—è®¡ç®—æ—¶é—´æˆ³")
            
        except Exception as e:
            logger.warning(f"è·å–åŒºå—æ—¶é—´å¤±è´¥: {e}ï¼Œä½¿ç”¨ä¼°ç®—å€¼")
            # ä½¿ç”¨å®Œå…¨ä¼°ç®—
            now = datetime.now()
            current_block = self.w3.eth.block_number
            for block_num in unique_blocks:
                if block_num not in self._block_timestamps:
                    seconds_ago = (current_block - block_num) * 2
                    self._block_timestamps[block_num] = now - timedelta(seconds=seconds_ago)
    
    def fetch_recent_trades(self, num_blocks: int = 100) -> List[RealTrade]:
        """
        è·å–æœ€è¿‘åŒºå—çš„çœŸå®äº¤æ˜“æ•°æ®
        
        Args:
            num_blocks: è¦è·å–çš„åŒºå—æ•°é‡
        
        Returns:
            çœŸå®äº¤æ˜“åˆ—è¡¨
        """
        if not self.w3 or not self.w3.is_connected():
            logger.error("æœªè¿æ¥åˆ°èŠ‚ç‚¹")
            return []
        
        current_block = self.w3.eth.block_number
        from_block = current_block - num_blocks
        
        logger.info(f"ğŸ“¡ è·å–åŒºå— {from_block} åˆ° {current_block} çš„äº¤æ˜“æ•°æ®...")
        
        all_trades = []
        all_events = defaultdict(list)  # tx_hash -> events
        all_order_logs = []  # æ”¶é›†æ‰€æœ‰ order logs ç”¨äºæ‰¹é‡é¢„å–æ—¶é—´
        
        # åˆ†æ‰¹è·å–æ—¥å¿— (Chainstack æ”¯æŒæ›´å¤§çš„èŒƒå›´)
        batch_size = 50  # æ¯æ‰¹50ä¸ªåŒºå—
        
        for batch_start in range(from_block, current_block + 1, batch_size):
            batch_end = min(batch_start + batch_size - 1, current_block)
            
            try:
                # è·å– OrderFilled äº‹ä»¶
                order_logs = self.w3.eth.get_logs({
                    'address': [CTF_EXCHANGE, NEG_RISK_EXCHANGE],
                    'topics': [[ORDER_FILLED_TOPIC]],
                    'fromBlock': batch_start,
                    'toBlock': batch_end,
                })
                
                # è·å– PositionSplit äº‹ä»¶
                split_logs = self.w3.eth.get_logs({
                    'address': CONDITIONAL_TOKENS,
                    'topics': [[POSITION_SPLIT_TOPIC]],
                    'fromBlock': batch_start,
                    'toBlock': batch_end,
                })
                
                # è·å– PositionsMerge äº‹ä»¶
                merge_logs = self.w3.eth.get_logs({
                    'address': CONDITIONAL_TOKENS,
                    'topics': [[POSITIONS_MERGE_TOPIC]],
                    'fromBlock': batch_start,
                    'toBlock': batch_end,
                })
                
                logger.info(f"   åŒºå— {batch_start}-{batch_end}: {len(order_logs)} äº¤æ˜“, {len(split_logs)} Split, {len(merge_logs)} Merge")
                
                # å…ˆæ”¶é›†æ‰€æœ‰ logs
                all_order_logs.extend(order_logs)
                
                # è®°å½• Split/Merge äº‹ä»¶
                for log in split_logs:
                    tx_hash = log['transactionHash'].hex()
                    stakeholder = self._topic_to_address(log['topics'][1])
                    all_events[tx_hash].append(('split', stakeholder))
                
                for log in merge_logs:
                    tx_hash = log['transactionHash'].hex()
                    stakeholder = self._topic_to_address(log['topics'][1])
                    all_events[tx_hash].append(('merge', stakeholder))
                
                time.sleep(0.1)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                logger.warning(f"   è·å–åŒºå— {batch_start}-{batch_end} å¤±è´¥: {e}")
                continue
        
        # æ‰¹é‡é¢„å–æ‰€æœ‰éœ€è¦çš„åŒºå—æ—¶é—´æˆ³
        if all_order_logs:
            unique_blocks = list(set(log['blockNumber'] for log in all_order_logs))
            logger.info(f"ğŸ“¦ é¢„å– {len(unique_blocks)} ä¸ªå”¯ä¸€åŒºå—çš„æ—¶é—´æˆ³...")
            self._prefetch_block_timestamps(unique_blocks)
        
        # è§£ææ‰€æœ‰ OrderFilled äº‹ä»¶
        logger.info(f"ğŸ”„ è§£æ {len(all_order_logs)} ç¬”äº¤æ˜“...")
        for log in all_order_logs:
            trade = self._decode_order_filled(log)
            if trade:
                all_trades.append(trade)
                tx_hash = trade.tx_hash
                all_events[tx_hash].append(('trade', trade))
        
        # æ„å»ºäº¤æ˜“æ†ç»‘å¹¶åˆ†æ
        self._build_and_analyze_bundles(all_events)
        
        # æ›´æ–°å¸‚åœºå¥åº·åº¦
        self._update_market_health(all_trades)
        
        with self._lock:
            self.trades.extend(all_trades)
            self._last_block = current_block
        
        logger.info(f"âœ… å…±è·å– {len(all_trades)} ç¬”çœŸå®äº¤æ˜“")
        
        return all_trades
    
    def _decode_order_filled(self, log: Dict) -> Optional[RealTrade]:
        """è§£ç  OrderFilled äº‹ä»¶"""
        try:
            topics = log['topics']
            data = log['data']
            
            # indexed å‚æ•°
            order_hash = topics[1].hex() if len(topics) > 1 else ""
            maker = self._topic_to_address(topics[2]) if len(topics) > 2 else ""
            taker = self._topic_to_address(topics[3]) if len(topics) > 3 else ""
            
            # é indexed å‚æ•°
            if isinstance(data, str):
                data = bytes.fromhex(data[2:]) if data.startswith('0x') else bytes.fromhex(data)
            
            if len(data) >= 160:  # 5 * 32 bytes
                maker_asset_id = int.from_bytes(data[0:32], 'big')
                taker_asset_id = int.from_bytes(data[32:64], 'big')
                maker_amount = int.from_bytes(data[64:96], 'big')
                taker_amount = int.from_bytes(data[96:128], 'big')
                fee = int.from_bytes(data[128:160], 'big')
            else:
                return None
            
            # è·å–åŒºå—æ—¶é—´ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            block_number = log['blockNumber']
            timestamp = self._get_block_timestamp(block_number)
            
            return RealTrade(
                tx_hash=log['transactionHash'].hex(),
                block_number=log['blockNumber'],
                log_index=log['logIndex'],
                timestamp=timestamp,
                contract=log['address'],
                order_hash=order_hash,
                maker=maker,
                taker=taker,
                maker_asset_id=maker_asset_id,
                taker_asset_id=taker_asset_id,
                maker_amount=maker_amount,
                taker_amount=taker_amount,
                fee=fee,
            )
        except Exception as e:
            logger.warning(f"è§£ç äº¤æ˜“å¤±è´¥: {e}")
            return None
    
    def _topic_to_address(self, topic) -> str:
        """å°† topic è½¬æ¢ä¸ºåœ°å€"""
        if isinstance(topic, bytes):
            return Web3.to_checksum_address(topic[-20:])
        topic_hex = topic.hex() if hasattr(topic, 'hex') else str(topic)
        if topic_hex.startswith('0x'):
            topic_hex = topic_hex[2:]
        return Web3.to_checksum_address('0x' + topic_hex[-40:])
    
    def _build_and_analyze_bundles(self, events: Dict[str, List]):
        """æ„å»ºå¹¶åˆ†æäº¤æ˜“æ†ç»‘"""
        bundles = []
        
        for tx_hash, event_list in events.items():
            trades = [e[1] for e in event_list if e[0] == 'trade']
            splits = [e[1] for e in event_list if e[0] == 'split']
            merges = [e[1] for e in event_list if e[0] == 'merge']
            
            if not trades:
                continue
            
            bundle = TransactionBundle(
                tx_hash=tx_hash,
                block_number=trades[0].block_number,
                timestamp=trades[0].timestamp,
                trades=trades,
                has_split=len(splits) > 0,
                has_merge=len(merges) > 0,
                split_addresses=set(s.lower() for s in splits),
                merge_addresses=set(m.lower() for m in merges),
            )
            
            bundle.analyze()
            bundles.append(bundle)
            
            # ç”Ÿæˆè­¦æŠ¥
            if bundle.is_atomic_wash:
                self.alerts.append({
                    'id': f"ATOMIC_{tx_hash[:16]}",
                    'timestamp': bundle.timestamp.isoformat(),
                    'type': 'ATOMIC_WASH',
                    'tx_hash': tx_hash,
                    'trade_count': len(trades),
                    'volume': float(bundle.total_volume),
                    'confidence': bundle.wash_confidence,
                    'addresses': list(bundle.involved_addresses)[:5],
                })
        
        with self._lock:
            self.bundles.extend(bundles)
    
    def _update_market_health(self, trades: List[RealTrade]):
        """æ›´æ–°å¸‚åœºå¥åº·åº¦"""
        for trade in trades:
            token_id = trade.token_id
            
            if token_id not in self.market_health:
                self.market_health[token_id] = MarketHealth(token_id=token_id)
            
            health = self.market_health[token_id]
            volume = Decimal(str(trade.size * trade.price))
            
            health.total_volume += volume
            health.total_trades += 1
            health.unique_traders.add(trade.maker.lower())
            health.unique_traders.add(trade.taker.lower())
            
            if trade.is_wash:
                health.wash_volume += volume
                health.wash_trades += 1
                health.suspicious_addresses.add(trade.maker.lower())
                health.suspicious_addresses.add(trade.taker.lower())
            else:
                health.organic_volume += volume
    
    def detect_self_trades(self):
        """æ£€æµ‹è‡ªæˆäº¤"""
        with self._lock:
            for trade in self.trades:
                if trade.maker.lower() == trade.taker.lower():
                    trade.is_wash = True
                    trade.wash_type = "SELF_TRADE"
                    trade.wash_confidence = 1.0
                    
                    # æ›´æ–°å¸‚åœºå¥åº·åº¦
                    if trade.token_id in self.market_health:
                        health = self.market_health[trade.token_id]
                        volume = Decimal(str(trade.size * trade.price))
                        if not hasattr(trade, '_counted_as_wash'):
                            health.wash_volume += volume
                            health.wash_trades += 1
                            health.suspicious_addresses.add(trade.maker.lower())
                            trade._counted_as_wash = True
                    
                    self.alerts.append({
                        'id': f"SELF_{trade.tx_hash[:16]}",
                        'timestamp': trade.timestamp.isoformat(),
                        'type': 'SELF_TRADE',
                        'tx_hash': trade.tx_hash,
                        'trade_count': 1,
                        'volume': trade.size * trade.price,
                        'confidence': 1.0,
                        'addresses': [trade.maker],
                    })
    
    def detect_circular_trades(self, time_window_seconds: int = 60):
        """æ£€æµ‹ç¯å½¢äº¤æ˜“"""
        with self._lock:
            sorted_trades = sorted(self.trades, key=lambda t: t.timestamp)
            
            for i, trade in enumerate(sorted_trades):
                if trade.is_wash:
                    continue
                
                for j in range(i + 1, len(sorted_trades)):
                    later = sorted_trades[j]
                    
                    time_diff = (later.timestamp - trade.timestamp).total_seconds()
                    if time_diff > time_window_seconds:
                        break
                    
                    # æ£€æµ‹ Aâ†’B, Bâ†’A æ¨¡å¼
                    if (trade.taker.lower() == later.maker.lower() and
                        trade.maker.lower() == later.taker.lower() and
                        trade.token_id == later.token_id):
                        
                        trade.is_wash = True
                        trade.wash_type = "CIRCULAR"
                        trade.wash_confidence = 0.85
                        
                        later.is_wash = True
                        later.wash_type = "CIRCULAR"
                        later.wash_confidence = 0.85
                        
                        self.alerts.append({
                            'id': f"CIRC_{trade.tx_hash[:8]}_{later.tx_hash[:8]}",
                            'timestamp': trade.timestamp.isoformat(),
                            'type': 'CIRCULAR_TRADE',
                            'tx_hash': trade.tx_hash,
                            'trade_count': 2,
                            'volume': trade.size * trade.price + later.size * later.price,
                            'confidence': 0.85,
                            'addresses': [trade.maker, trade.taker],
                            'time_diff': time_diff,
                        })
    
    def get_summary(self) -> Dict:
        """è·å–åˆ†ææ‘˜è¦"""
        with self._lock:
            total_volume = sum(float(h.total_volume) for h in self.market_health.values())
            wash_volume = sum(float(h.wash_volume) for h in self.market_health.values())
            total_trades = len(self.trades)
            wash_trades = sum(1 for t in self.trades if t.is_wash)
            
            return {
                'total_trades': total_trades,
                'wash_trades': wash_trades,
                'wash_ratio': wash_trades / total_trades if total_trades > 0 else 0,
                'total_volume': total_volume,
                'wash_volume': wash_volume,
                'organic_volume': total_volume - wash_volume,
                'organic_ratio': (total_volume - wash_volume) / total_volume if total_volume > 0 else 1.0,
                'markets_analyzed': len(self.market_health),
                'alerts_count': len(self.alerts),
                'last_block': self._last_block,
            }
    
    def get_wash_trades(self, limit: int = 50) -> List[Dict]:
        """è·å–åˆ·é‡äº¤æ˜“"""
        with self._lock:
            wash = sorted([t for t in self.trades if t.is_wash],
                         key=lambda x: x.wash_confidence, reverse=True)
            return [
                {
                    'tx_hash': t.tx_hash,
                    'block': t.block_number,
                    'timestamp': t.timestamp.isoformat(),
                    'token_id': t.token_id[:20] + '...' if len(t.token_id) > 20 else t.token_id,
                    'side': t.side,
                    'price': t.price,
                    'size': t.size,
                    'volume': t.size * t.price,
                    'maker': t.maker,
                    'taker': t.taker,
                    'type': t.wash_type,
                    'confidence': t.wash_confidence,
                }
                for t in wash[:limit]
            ]
    
    def get_all_health(self) -> List[Dict]:
        """è·å–æ‰€æœ‰å¸‚åœºå¥åº·åº¦"""
        with self._lock:
            return sorted([
                {
                    'token_id': h.token_id[:20] + '...' if len(h.token_id) > 20 else h.token_id,
                    'health_score': h.health_score,
                    'wash_ratio': h.wash_ratio,
                    'total_volume': float(h.total_volume),
                    'organic_volume': float(h.organic_volume),
                    'total_trades': h.total_trades,
                    'unique_traders': len(h.unique_traders),
                    'suspicious_count': len(h.suspicious_addresses),
                }
                for h in self.market_health.values()
                if h.total_trades > 0
            ], key=lambda x: x['health_score'])
    
    def get_alerts(self, limit: int = 50) -> List[Dict]:
        """è·å–è­¦æŠ¥"""
        with self._lock:
            return sorted(self.alerts, key=lambda x: x['confidence'], reverse=True)[:limit]


# ============================================================================
# æµå¼ç›‘æ§
# ============================================================================

class StreamingMonitor:
    """æµå¼ç›‘æ§å™¨ - æŒç»­è·å–æ–°æ•°æ®"""
    
    def __init__(self, forensics: OnChainForensics):
        self.forensics = forensics
        self._running = False
        self._thread = None
        self._callbacks: List[Callable] = []
    
    def add_callback(self, callback: Callable):
        self._callbacks.append(callback)
    
    def _notify(self, event: Dict):
        for cb in self._callbacks:
            try:
                cb(event)
            except Exception as e:
                logger.error(f"Callback error: {e}")
    
    def start(self, poll_interval: float = 10.0, blocks_per_poll: int = 20):
        """å¯åŠ¨æµå¼ç›‘æ§"""
        if self._running:
            return
        
        self._running = True
        self._thread = threading.Thread(
            target=self._poll_loop,
            args=(poll_interval, blocks_per_poll),
            daemon=True
        )
        self._thread.start()
        logger.info("ğŸ“¡ æµå¼ç›‘æ§å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        self._running = False
        if self._thread:
            self._thread.join(timeout=5)
        logger.info("â¹ï¸ æµå¼ç›‘æ§å·²åœæ­¢")
    
    def _poll_loop(self, interval: float, blocks: int):
        while self._running:
            try:
                trades = self.forensics.fetch_recent_trades(num_blocks=blocks)
                
                if trades:
                    # è¿è¡Œæ£€æµ‹
                    self.forensics.detect_self_trades()
                    self.forensics.detect_circular_trades()
                    
                    summary = self.forensics.get_summary()
                    self._notify({
                        'type': 'update',
                        'new_trades': len(trades),
                        **summary,
                    })
                
            except Exception as e:
                logger.error(f"è½®è¯¢é”™è¯¯: {e}")
            
            time.sleep(interval)
    
    @property
    def is_running(self) -> bool:
        return self._running


# ============================================================================
# å…¨å±€å®ä¾‹
# ============================================================================

_forensics: Optional[OnChainForensics] = None
_monitor: Optional[StreamingMonitor] = None


def get_forensics() -> OnChainForensics:
    global _forensics
    if _forensics is None:
        _forensics = OnChainForensics()
    return _forensics


def get_monitor() -> StreamingMonitor:
    global _monitor, _forensics
    if _forensics is None:
        _forensics = OnChainForensics()
    if _monitor is None:
        _monitor = StreamingMonitor(_forensics)
    return _monitor


# ============================================================================
# æµ‹è¯•
# ============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("PolySleuth - çœŸå®é“¾ä¸Šæ•°æ®å–è¯åˆ†æ")
    print("=" * 60)
    print(f"RPC: {POLYGON_RPC_URL[:50]}...")
    print()
    
    forensics = OnChainForensics()
    
    if not forensics.w3 or not forensics.w3.is_connected():
        print("âŒ æ— æ³•è¿æ¥åˆ°èŠ‚ç‚¹ï¼Œé€€å‡º")
        exit(1)
    
    # è·å–æœ€è¿‘ 100 ä¸ªåŒºå—çš„æ•°æ®
    print("\nğŸ“¡ è·å–æœ€è¿‘ 100 ä¸ªåŒºå—çš„çœŸå®äº¤æ˜“æ•°æ®...")
    trades = forensics.fetch_recent_trades(num_blocks=100)
    
    if trades:
        # è¿è¡Œæ£€æµ‹
        print("\nğŸ” è¿è¡Œåˆ·é‡æ£€æµ‹ç®—æ³•...")
        forensics.detect_self_trades()
        forensics.detect_circular_trades()
        
        # æ˜¾ç¤ºç»“æœ
        summary = forensics.get_summary()
        print(f"\nğŸ“Š åˆ†ææ‘˜è¦:")
        print(f"   æ€»äº¤æ˜“æ•°: {summary['total_trades']}")
        print(f"   å¯ç–‘äº¤æ˜“: {summary['wash_trades']}")
        print(f"   åˆ·é‡æ¯”ä¾‹: {summary['wash_ratio']:.2%}")
        print(f"   æ€»äº¤æ˜“é‡: ${summary['total_volume']:,.2f}")
        print(f"   æœ‰æœºæ¯”ä¾‹: {summary['organic_ratio']:.2%}")
        print(f"   è­¦æŠ¥æ•°é‡: {summary['alerts_count']}")
        
        # æ˜¾ç¤ºå¯ç–‘äº¤æ˜“
        wash_trades = forensics.get_wash_trades(limit=5)
        if wash_trades:
            print(f"\nğŸš¨ Top å¯ç–‘äº¤æ˜“:")
            for i, t in enumerate(wash_trades, 1):
                print(f"   {i}. [{t['type']}] {t['tx_hash'][:20]}... ${t['volume']:.2f} (ç½®ä¿¡åº¦: {t['confidence']:.0%})")
        
        # æ˜¾ç¤ºå¸‚åœºå¥åº·åº¦
        health = forensics.get_all_health()[:5]
        if health:
            print(f"\nğŸ¥ ä½å¥åº·åº¦å¸‚åœº:")
            for h in health:
                emoji = "ğŸ”´" if h['health_score'] < 40 else "ğŸŸ " if h['health_score'] < 60 else "ğŸŸ¡"
                print(f"   {emoji} {h['token_id']} - åˆ†æ•°: {h['health_score']}, åˆ·é‡: {h['wash_ratio']:.1%}")
    else:
        print("âš ï¸ æœªè·å–åˆ°äº¤æ˜“æ•°æ®")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
