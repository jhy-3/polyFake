"""
PolySleuth - æ•°æ®å­˜å‚¨æœåŠ¡

æ”¯æŒï¼š
- SQLite æŒä¹…åŒ–å­˜å‚¨
- å†…å­˜ç¼“å­˜å¿«é€ŸæŸ¥è¯¢
- æµå¼æ•°æ®å†™å…¥
- è‡ªåŠ¨åŒæ­¥æœºåˆ¶
"""
import json
import threading
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set, Callable, Any
from collections import defaultdict, deque
from dataclasses import dataclass, field
from decimal import Decimal
import logging

from sqlalchemy.orm import Session
from sqlalchemy import desc, func

from ..models import (
    TradeDB, AlertDB, MarketCacheDB,
    TradeResponse, AlertResponse, MarketSummary, MarketHealth, SystemStats,
    SessionLocal, init_db
)
from ..config import MAX_TRADES_IN_MEMORY, MAX_ALERTS_IN_MEMORY

logger = logging.getLogger(__name__)


# ============================================================================
# å†…å­˜æ•°æ®ç»“æ„
# ============================================================================

@dataclass
class MemoryTrade:
    """å†…å­˜ä¸­çš„äº¤æ˜“è®°å½•"""
    tx_hash: str
    log_index: int
    block_number: int
    timestamp: datetime
    contract: str
    order_hash: str
    maker: str
    taker: str
    token_id: str
    side: str
    price: float
    size: float
    volume: float
    fee: int = 0
    
    is_wash: bool = False
    wash_type: str = "NONE"
    wash_confidence: float = 0.0
    
    _persisted: bool = False  # æ˜¯å¦å·²æŒä¹…åŒ–åˆ°æ•°æ®åº“


@dataclass
class MemoryAlert:
    """å†…å­˜ä¸­çš„è­¦æŠ¥"""
    alert_id: str
    timestamp: datetime
    alert_type: str
    severity: str
    tx_hash: str = ""
    token_id: str = ""
    trade_count: int = 1
    volume: float = 0.0
    confidence: float = 0.0
    addresses: List[str] = field(default_factory=list)
    details: Dict = field(default_factory=dict)
    
    _persisted: bool = False


@dataclass  
class MarketHealthData:
    """å¸‚åœºå¥åº·åº¦æ•°æ®"""
    token_id: str
    total_trades: int = 0
    wash_trades: int = 0
    total_volume: Decimal = Decimal(0)
    organic_volume: Decimal = Decimal(0)
    wash_volume: Decimal = Decimal(0)
    unique_traders: Set[str] = field(default_factory=set)
    suspicious_addresses: Set[str] = field(default_factory=set)
    
    @property
    def wash_ratio(self) -> float:
        if self.total_trades == 0:
            return 0.0
        return self.wash_trades / self.total_trades
    
    @property
    def health_score(self) -> float:
        """è®¡ç®—å¥åº·åº¦è¯„åˆ† (0-100)"""
        score = 100.0
        
        # åˆ·é‡æ¯”ä¾‹æ‰£åˆ† (æœ€å¤š -50)
        score -= min(self.wash_ratio * 100, 50)
        
        # äº¤æ˜“è€…æ•°é‡åŠ åˆ†
        trader_count = len(self.unique_traders)
        if trader_count >= 100:
            score += 10
        elif trader_count >= 50:
            score += 5
        elif trader_count < 5:
            score -= 10
        
        # å¯ç–‘åœ°å€æ‰£åˆ†
        if len(self.suspicious_addresses) > 0:
            suspicious_ratio = len(self.suspicious_addresses) / max(trader_count, 1)
            score -= min(suspicious_ratio * 30, 20)
        
        return max(0, min(100, score))


# ============================================================================
# æ•°æ®å­˜å‚¨æœåŠ¡
# ============================================================================

class DataStore:
    """
    æ•°æ®å­˜å‚¨æœåŠ¡
    
    æ¶æ„:
    - å†…å­˜å±‚: å¿«é€Ÿè¯»å†™ï¼Œå­˜å‚¨æœ€è¿‘æ•°æ®
    - æŒä¹…å±‚: SQLite å­˜å‚¨å†å²æ•°æ®
    - åŒæ­¥æœºåˆ¶: åå°çº¿ç¨‹å®šæœŸåŒæ­¥åˆ°æ•°æ®åº“
    """
    
    def __init__(self, sync_interval: float = 10.0):
        # å†…å­˜å­˜å‚¨
        self._trades: deque[MemoryTrade] = deque(maxlen=MAX_TRADES_IN_MEMORY)
        self._alerts: deque[MemoryAlert] = deque(maxlen=MAX_ALERTS_IN_MEMORY)
        self._market_health: Dict[str, MarketHealthData] = {}
        self._market_cache: Dict[str, Dict] = {}  # token_id -> market info
        self._event_cache: Dict[str, Dict] = {}  # slug -> event info (åŒ…å«æ‰€æœ‰token_ids)
        self._market_fetch_queue: deque[str] = deque()
        self._market_fetch_pending: Set[str] = set()
        self._market_fetch_thread: Optional[threading.Thread] = None
        
        # ç´¢å¼•
        self._trades_by_hash: Dict[str, List[MemoryTrade]] = defaultdict(list)
        self._trades_by_address: Dict[str, List[MemoryTrade]] = defaultdict(list)
        self._trades_by_token: Dict[str, List[MemoryTrade]] = defaultdict(list)
        
        # ç»Ÿè®¡
        self._total_trades = 0
        self._total_wash = 0
        self._total_volume = 0.0
        self._wash_volume = 0.0
        self._last_block = 0
        
        # åŒæ­¥æ§åˆ¶
        self._sync_interval = sync_interval
        self._sync_thread: Optional[threading.Thread] = None
        self._running = False
        self._lock = threading.RLock()
        self._pending_trades: List[MemoryTrade] = []
        self._pending_alerts: List[MemoryAlert] = []
        
        # WebSocket å›è°ƒ
        self._ws_callbacks: List[Callable] = []
        
        # åˆå§‹åŒ–æ•°æ®åº“
        init_db()
        
        # ä»æ•°æ®åº“åŠ è½½ç¼“å­˜
        self._load_market_cache()

        # å¯åŠ¨å¸‚åœºä¿¡æ¯åå°è¡¥å…¨çº¿ç¨‹
        self._start_market_fetcher()

    def _start_market_fetcher(self):
        if self._market_fetch_thread and self._market_fetch_thread.is_alive():
            return
        self._market_fetch_thread = threading.Thread(target=self._market_fetch_loop, daemon=True)
        self._market_fetch_thread.start()

    def _schedule_market_fetch(self, token_id: str):
        if not token_id:
            return
        with self._lock:
            if token_id in self._market_fetch_pending:
                return
            self._market_fetch_pending.add(token_id)
            self._market_fetch_queue.append(token_id)

    def _market_fetch_loop(self):
        """åå°è¡¥å…¨ç¼ºå¤±çš„å¸‚åœºä¿¡æ¯"""
        while True:
            try:
                token_id = None
                with self._lock:
                    if self._market_fetch_queue:
                        token_id = self._market_fetch_queue.popleft()
                if not token_id:
                    time.sleep(1)
                    continue

                # å¦‚æœå·²ç»æœ‰äº†åˆ™è·³è¿‡
                info = self._market_cache.get(token_id, {})
                if info.get('question'):
                    with self._lock:
                        self._market_fetch_pending.discard(token_id)
                    continue

                try:
                    import requests
                    resp = requests.get(
                        f"https://gamma-api.polymarket.com/markets/{token_id}",
                        timeout=5
                    )
                    if resp.status_code == 200:
                        market_data = resp.json()
                        if market_data and isinstance(market_data, dict):
                            question = market_data.get('question', '')
                            outcome = market_data.get('outcome', '')
                            # é‡è¦ï¼šä» events[0].slug è·å– event slugï¼ˆPolymarket URL éœ€è¦ï¼‰
                            events = market_data.get('events', [])
                            event_slug = events[0].get('slug', '') if events else ''
                            slug = event_slug or market_data.get('slug', '')
                            market_id = str(
                                market_data.get('eventId', '')
                                or market_data.get('event_id', '')
                                or market_data.get('market_id', '')
                                or market_data.get('id', '')
                            )

                            if question:
                                self.cache_market(token_id, {
                                    'question': question,
                                    'slug': slug,
                                    'outcome': outcome,
                                    'market_id': market_id,
                                })
                except Exception as e:
                    logger.debug(f"åå°è¡¥å…¨å¸‚åœºå¤±è´¥: {token_id[:16]}... - {e}")
                finally:
                    with self._lock:
                        self._market_fetch_pending.discard(token_id)
            except Exception:
                time.sleep(1)
    
    def _load_market_cache(self):
        """ä»æ•°æ®åº“åŠ è½½å¸‚åœºç¼“å­˜"""
        try:
            db = SessionLocal()
            try:
                markets = db.query(MarketCacheDB).all()
                for m in markets:
                    self._market_cache[m.token_id] = {
                        'question': m.question,
                        'slug': m.slug,
                        'outcome': m.outcome,
                        'condition_id': m.condition_id,
                        'market_id': getattr(m, 'market_id', ''),
                    }
                logger.info(f"âœ… ä»æ•°æ®åº“åŠ è½½ {len(self._market_cache)} ä¸ªå¸‚åœºç¼“å­˜")
            finally:
                db.close()
        except Exception as e:
            logger.warning(f"åŠ è½½å¸‚åœºç¼“å­˜å¤±è´¥: {e}")
    
    def start_sync(self):
        """å¯åŠ¨åå°åŒæ­¥çº¿ç¨‹"""
        if self._running:
            return
        
        self._running = True
        self._sync_thread = threading.Thread(target=self._sync_loop, daemon=True)
        self._sync_thread.start()
        logger.info("âœ… åå°åŒæ­¥çº¿ç¨‹å·²å¯åŠ¨")
    
    def stop_sync(self):
        """åœæ­¢åå°åŒæ­¥"""
        self._running = False
        if self._sync_thread:
            self._sync_thread.join(timeout=5)
        # æœ€åä¸€æ¬¡åŒæ­¥
        self._sync_to_db()
        logger.info("âœ… åå°åŒæ­¥çº¿ç¨‹å·²åœæ­¢")
    
    def stop(self):
        """åœæ­¢æœåŠ¡ï¼ˆåˆ«åï¼‰"""
        self.stop_sync()
    
    def _sync_loop(self):
        """åå°åŒæ­¥å¾ªç¯"""
        while self._running:
            time.sleep(self._sync_interval)
            try:
                self._sync_to_db()
            except Exception as e:
                logger.error(f"åŒæ­¥å¤±è´¥: {e}")
    
    def _sync_to_db(self):
        """åŒæ­¥å†…å­˜æ•°æ®åˆ°æ•°æ®åº“"""
        with self._lock:
            trades_to_save = self._pending_trades.copy()
            alerts_to_save = self._pending_alerts.copy()
            self._pending_trades.clear()
            self._pending_alerts.clear()
        
        if not trades_to_save and not alerts_to_save:
            return
        
        db = SessionLocal()
        try:
            # æ‰¹é‡æ’å…¥äº¤æ˜“ï¼ˆä½¿ç”¨ INSERT OR IGNORE è¯­ä¹‰ï¼‰
            if trades_to_save:
                saved_count = 0
                for trade in trades_to_save:
                    try:
                        # å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨
                        exists = db.query(TradeDB).filter(
                            TradeDB.tx_hash == trade.tx_hash,
                            TradeDB.log_index == trade.log_index
                        ).first()
                        
                        if not exists:
                            db_trade = TradeDB(
                                tx_hash=trade.tx_hash,
                                log_index=trade.log_index,
                                block_number=trade.block_number,
                                timestamp=trade.timestamp,
                                contract=trade.contract,
                                order_hash=trade.order_hash,
                                maker=trade.maker,
                                taker=trade.taker,
                                token_id=trade.token_id,
                                side=trade.side,
                                price=trade.price,
                                size=trade.size,
                                volume=trade.volume,
                                fee=trade.fee,
                                is_wash=trade.is_wash,
                                wash_type=trade.wash_type,
                                wash_confidence=trade.wash_confidence,
                            )
                            db.add(db_trade)
                            saved_count += 1
                    except Exception as e:
                        pass  # å¿½ç•¥é‡å¤
                
                try:
                    db.commit()
                    if saved_count > 0:
                        logger.debug(f"ğŸ’¾ åŒæ­¥ {saved_count} ç¬”äº¤æ˜“åˆ°æ•°æ®åº“")
                except Exception as e:
                    # é™é»˜å¤„ç†é‡å¤é”®é”™è¯¯ï¼ˆå¤šçº¿ç¨‹ç«äº‰æ¡ä»¶ï¼‰
                    if 'UNIQUE constraint failed' not in str(e):
                        logger.error(f"äº¤æ˜“åŒæ­¥å¤±è´¥: {e}")
                    db.rollback()
            
            # æ‰¹é‡æ’å…¥è­¦æŠ¥
            if alerts_to_save:
                saved_count = 0
                for alert in alerts_to_save:
                    try:
                        exists = db.query(AlertDB).filter(
                            AlertDB.alert_id == alert.alert_id
                        ).first()
                        
                        if not exists:
                            db_alert = AlertDB(
                                alert_id=alert.alert_id,
                                timestamp=alert.timestamp,
                                alert_type=alert.alert_type,
                                severity=alert.severity,
                                tx_hash=alert.tx_hash,
                                token_id=alert.token_id,
                                trade_count=alert.trade_count,
                                volume=alert.volume,
                                confidence=alert.confidence,
                                addresses=json.dumps(alert.addresses),
                                details=json.dumps(alert.details),
                            )
                            db.add(db_alert)
                            saved_count += 1
                    except Exception as e:
                        pass
                
                try:
                    db.commit()
                    if saved_count > 0:
                        logger.debug(f"ğŸ’¾ åŒæ­¥ {saved_count} ä¸ªè­¦æŠ¥åˆ°æ•°æ®åº“")
                except Exception as e:
                    # é™é»˜å¤„ç†é‡å¤é”®é”™è¯¯ï¼ˆå¤šçº¿ç¨‹ç«äº‰æ¡ä»¶ï¼‰
                    if 'UNIQUE constraint failed' not in str(e):
                        logger.error(f"è­¦æŠ¥åŒæ­¥å¤±è´¥: {e}")
                    db.rollback()
        
        except Exception as e:
            # åªè®°å½•éé‡å¤é”®çš„é”™è¯¯
            if 'UNIQUE constraint failed' not in str(e):
                logger.error(f"æ•°æ®åº“åŒæ­¥å¤±è´¥: {e}")
            try:
                db.rollback()
            except:
                pass
        finally:
            db.close()
    
    # ========================================================================
    # å†™å…¥æ¥å£
    # ========================================================================
    
    def add_trade(self, trade: MemoryTrade, notify: bool = True):
        """æ·»åŠ äº¤æ˜“ï¼ˆæµå¼å†™å…¥ï¼‰"""
        with self._lock:
            # æ·»åŠ åˆ°å†…å­˜
            self._trades.append(trade)
            
            # æ›´æ–°ç´¢å¼•
            self._trades_by_hash[trade.tx_hash].append(trade)
            self._trades_by_address[trade.maker.lower()].append(trade)
            self._trades_by_address[trade.taker.lower()].append(trade)
            self._trades_by_token[trade.token_id].append(trade)
            
            # æ›´æ–°ç»Ÿè®¡
            self._total_trades += 1
            self._total_volume += trade.volume
            if trade.block_number > self._last_block:
                self._last_block = trade.block_number
            
            if trade.is_wash:
                self._total_wash += 1
                self._wash_volume += trade.volume
            
            # æ›´æ–°å¸‚åœºå¥åº·åº¦
            self._update_market_health(trade)
            
            # åŠ å…¥å¾…åŒæ­¥é˜Ÿåˆ—
            self._pending_trades.append(trade)
        
        # é€šçŸ¥ WebSocket
        if notify:
            self._notify_ws('trade', self._trade_to_response(trade))
    
    def add_alert(self, alert: MemoryAlert, notify: bool = True):
        """æ·»åŠ è­¦æŠ¥"""
        with self._lock:
            self._alerts.append(alert)
            self._pending_alerts.append(alert)
        
        if notify:
            self._notify_ws('alert', self._alert_to_response(alert))
    
    def _update_market_health(self, trade: MemoryTrade):
        """æ›´æ–°å¸‚åœºå¥åº·åº¦"""
        token_id = trade.token_id
        
        if token_id not in self._market_health:
            self._market_health[token_id] = MarketHealthData(token_id=token_id)
        
        health = self._market_health[token_id]
        health.total_trades += 1
        volume = Decimal(str(trade.volume))
        health.total_volume += volume
        health.unique_traders.add(trade.maker.lower())
        health.unique_traders.add(trade.taker.lower())
        
        if trade.is_wash:
            health.wash_trades += 1
            health.wash_volume += volume
            health.suspicious_addresses.add(trade.maker.lower())
            health.suspicious_addresses.add(trade.taker.lower())
        else:
            health.organic_volume += volume
    
    def mark_wash_trade(self, tx_hash: str, log_index: int, 
                        wash_type: str, confidence: float):
        """æ ‡è®°äº¤æ˜“ä¸ºåˆ·é‡"""
        with self._lock:
            for trade in self._trades_by_hash.get(tx_hash, []):
                if trade.log_index == log_index and not trade.is_wash:
                    trade.is_wash = True
                    trade.wash_type = wash_type
                    trade.wash_confidence = confidence
                    
                    self._total_wash += 1
                    self._wash_volume += trade.volume
                    
                    # æ›´æ–°å¥åº·åº¦
                    if trade.token_id in self._market_health:
                        health = self._market_health[trade.token_id]
                        health.wash_trades += 1
                        volume = Decimal(str(trade.volume))
                        health.wash_volume += volume
                        health.organic_volume -= volume
                        health.suspicious_addresses.add(trade.maker.lower())
                        health.suspicious_addresses.add(trade.taker.lower())
    
    def cache_market(self, token_id: str, info: Dict):
        """ç¼“å­˜å¸‚åœºä¿¡æ¯ï¼ˆå•ä¸ªtokenï¼‰"""
        with self._lock:
            self._market_cache[token_id] = info
        
        # å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“
        try:
            db = SessionLocal()
            try:
                cache = MarketCacheDB(
                    token_id=token_id,
                    question=info.get('question', ''),
                    slug=info.get('slug', ''),
                    outcome=info.get('outcome', ''),
                    condition_id=info.get('condition_id', ''),
                    market_id=info.get('market_id', ''),
                    updated_at=datetime.utcnow(),
                )
                db.merge(cache)
                db.commit()
            finally:
                db.close()
        except:
            pass
    
    def cache_market_event(self, slug: str, info: Dict):
        """ç¼“å­˜äº‹ä»¶çº§åˆ«çš„å¸‚åœºä¿¡æ¯ï¼ˆåŒ…å«æ‰€æœ‰token_idsï¼‰"""
        with self._lock:
            self._event_cache[slug] = info
    
    def get_event_by_slug(self, slug: str) -> Optional[Dict]:
        """æ ¹æ® slug è·å–äº‹ä»¶ä¿¡æ¯"""
        with self._lock:
            return self._event_cache.get(slug)
    
    def get_slug_by_token_id(self, token_id: str) -> Optional[str]:
        """æ ¹æ® token_id åæŸ¥ slug"""
        with self._lock:
            market_info = self._market_cache.get(token_id)
            if market_info:
                return market_info.get('slug')
            return None
    
    # ========================================================================
    # æŸ¥è¯¢æ¥å£
    # ========================================================================
    
    def get_trades(self, limit: int = 100, offset: int = 0,
                   token_id: Optional[str] = None,
                   address: Optional[str] = None,
                   is_wash: Optional[bool] = None,
                   side: Optional[str] = None,
                   start_time: Optional[datetime] = None,
                   end_time: Optional[datetime] = None) -> List[TradeResponse]:
        """è·å–äº¤æ˜“åˆ—è¡¨"""
        with self._lock:
            trades = list(self._trades)
        
        # è¿‡æ»¤
        if token_id:
            trades = [t for t in trades if t.token_id == token_id]
        if address:
            address = address.lower()
            trades = [t for t in trades if t.maker.lower() == address or t.taker.lower() == address]
        if is_wash is not None:
            trades = [t for t in trades if t.is_wash == is_wash]
        if side:
            trades = [t for t in trades if t.side == side]
        if start_time:
            trades = [t for t in trades if t.timestamp >= start_time]
        if end_time:
            trades = [t for t in trades if t.timestamp <= end_time]
        
        # æŒ‰æ—¶é—´å€’åº
        trades.sort(key=lambda t: t.timestamp, reverse=True)
        
        # åˆ†é¡µ
        trades = trades[offset:offset + limit]
        
        return [self._trade_to_response(t) for t in trades]
    
    def get_trade_by_hash(self, tx_hash: str) -> List[TradeResponse]:
        """æ ¹æ®äº¤æ˜“å“ˆå¸Œè·å–"""
        with self._lock:
            trades = self._trades_by_hash.get(tx_hash.lower(), [])
        return [self._trade_to_response(t) for t in trades]
    
    def get_alerts(self, limit: int = 50, 
                   offset: int = 0,
                   alert_type: Optional[str] = None,
                   severity: Optional[str] = None,
                   start_time: Optional[datetime] = None,
                   end_time: Optional[datetime] = None) -> List[AlertResponse]:
        """è·å–è­¦æŠ¥åˆ—è¡¨"""
        with self._lock:
            alerts = list(self._alerts)
        
        # è¿‡æ»¤
        if alert_type:
            alerts = [a for a in alerts if a.alert_type == alert_type]
        if severity:
            alerts = [a for a in alerts if a.severity == severity]
        if start_time:
            alerts = [a for a in alerts if a.timestamp >= start_time]
        if end_time:
            alerts = [a for a in alerts if a.timestamp <= end_time]
        
        # æŒ‰æ—¶é—´å€’åº
        alerts.sort(key=lambda a: a.timestamp, reverse=True)
        
        # åˆ†é¡µ
        alerts = alerts[offset:offset + limit]
        
        return [self._alert_to_response(a) for a in alerts]
    
    def get_market_summary(self, limit: int = 20) -> List[MarketSummary]:
        """è·å–å¸‚åœºæ±‡æ€»"""
        with self._lock:
            # æŒ‰ question èšåˆ
            question_stats = defaultdict(lambda: {
                'question': '',
                'token_ids': [],
                'trade_count': 0,
                'volume': 0.0,
                'wash_count': 0,
                'unique_traders': set(),
                'outcomes': [],
            })
            
            for token_id, health in self._market_health.items():
                market_info = self._market_cache.get(token_id, {})
                question = market_info.get('question', f"Token {token_id[:16]}...")
                outcome = market_info.get('outcome', '')
                
                stats = question_stats[question]
                stats['question'] = question
                stats['token_ids'].append(token_id)
                stats['trade_count'] += health.total_trades
                stats['volume'] += float(health.total_volume)
                stats['wash_count'] += health.wash_trades
                stats['unique_traders'].update(health.unique_traders)
                if outcome:
                    stats['outcomes'].append(outcome)
            
            # è½¬æ¢ä¸ºåˆ—è¡¨
            result = []
            for question, stats in question_stats.items():
                result.append(MarketSummary(
                    question=question,
                    token_ids=stats['token_ids'],
                    trade_count=stats['trade_count'],
                    volume=stats['volume'],
                    wash_count=stats['wash_count'],
                    wash_ratio=stats['wash_count'] / stats['trade_count'] if stats['trade_count'] > 0 else 0,
                    unique_traders=len(stats['unique_traders']),
                    outcomes=list(set(stats['outcomes'])),
                ))
            
            # æŒ‰äº¤æ˜“é‡æ’åº
            result.sort(key=lambda x: x.volume, reverse=True)
            return result[:limit]
    
    def get_market_health(self, token_id: Optional[str] = None) -> List[MarketHealth]:
        """è·å–å¸‚åœºå¥åº·åº¦"""
        with self._lock:
            if token_id:
                health = self._market_health.get(token_id)
                if health:
                    return [self._health_to_response(health)]
                return []
            
            result = []
            for health in self._market_health.values():
                if health.total_trades > 0:
                    result.append(self._health_to_response(health))
            
            result.sort(key=lambda x: x.health_score)
            return result
    
    def get_stats(self) -> SystemStats:
        """è·å–ç³»ç»Ÿç»Ÿè®¡"""
        with self._lock:
            return SystemStats(
                total_trades=self._total_trades,
                total_alerts=len(self._alerts),
                wash_trade_count=self._total_wash,
                total_volume=self._total_volume,
                wash_volume=self._wash_volume,
                unique_markets=len(self._market_health),
                unique_traders=len(self._trades_by_address),
            )
    
    def get_market_name(self, token_id: str) -> str:
        """è·å–å¸‚åœºåç§°"""
        info = self._market_cache.get(token_id, {})
        question = info.get('question', '')
        outcome = info.get('outcome', '')

        if not question:
            self._schedule_market_fetch(token_id)
        
        if question:
            display = question[:50] + '...' if len(question) > 50 else question
            return f"{display} ({outcome})" if outcome else display
        
        return f"Token {token_id[:16]}..."
    
    def get_market_info(self, token_id: str, fetch_if_missing: bool = False) -> dict:
        """
        è·å–å®Œæ•´å¸‚åœºä¿¡æ¯
        
        Args:
            token_id: Token ID
            fetch_if_missing: å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œæ˜¯å¦å‘èµ·ç½‘ç»œè¯·æ±‚è·å–ï¼ˆé»˜è®¤ False é¿å…é˜»å¡ï¼‰
        """
        info = self._market_cache.get(token_id, {})
        question = info.get('question', '')
        outcome = info.get('outcome', '')
        slug = info.get('slug', '')  # ç°åœ¨å­˜å‚¨çš„æ˜¯ event slugï¼Œæ— éœ€è§„èŒƒåŒ–

        if not question and not fetch_if_missing:
            self._schedule_market_fetch(token_id)
        
        # åªåœ¨æ˜ç¡®éœ€è¦æ—¶æ‰æŒ‰éœ€æŸ¥è¯¢APIï¼ˆé¿å…åœ¨å¾ªç¯ä¸­æ„å¤–è§¦å‘å¤§é‡è¯·æ±‚ï¼‰
        if not question and fetch_if_missing:
            try:
                import requests
                resp = requests.get(
                    f"https://gamma-api.polymarket.com/markets/{token_id}",
                    timeout=2
                )
                if resp.status_code == 200:
                    market_data = resp.json()
                    if market_data and isinstance(market_data, dict):
                        question = market_data.get('question', '')
                        outcome = market_data.get('outcome', '')
                        # é‡è¦ï¼šä» events[0].slug è·å– event slugï¼ˆPolymarket URL éœ€è¦ï¼‰
                        events = market_data.get('events', [])
                        event_slug = events[0].get('slug', '') if events else ''
                        slug = event_slug or market_data.get('slug', '')
                        market_id = str(market_data.get('market_id', ''))
                        
                        # ç¼“å­˜åˆ°å†…å­˜å’Œæ•°æ®åº“
                        if question:
                            self.cache_market(
                                token_id=token_id,
                                question=question,
                                outcome=outcome,
                                slug=slug,
                                market_id=market_id
                            )
                            logger.info(f"âœ… æŒ‰éœ€åŠ è½½å¸‚åœº: {question[:30]}...")
            except Exception as e:
                logger.debug(f"æŒ‰éœ€æŸ¥è¯¢å¤±è´¥: {token_id[:16]}... - {e}")
        
        display_name = question
        if question:
            display_name = question[:50] + '...' if len(question) > 50 else question
            if outcome:
                display_name = f"{display_name} ({outcome})"
        else:
            display_name = f"Token {token_id[:16]}..."
        
        polymarket_url = None
        if slug:
            polymarket_url = f"https://polymarket.com/event/{slug}"
        
        return {
            'name': display_name,
            'slug': slug,
            'polymarket_url': polymarket_url,
            'question': question,
            'outcome': outcome
        }
    
    # ========================================================================
    # WebSocket é€šçŸ¥
    # ========================================================================
    
    def register_ws_callback(self, callback: Callable):
        """æ³¨å†Œ WebSocket å›è°ƒ"""
        self._ws_callbacks.append(callback)
    
    def unregister_ws_callback(self, callback: Callable):
        """æ³¨é”€ WebSocket å›è°ƒ"""
        if callback in self._ws_callbacks:
            self._ws_callbacks.remove(callback)
    
    def _notify_ws(self, msg_type: str, data: Any):
        """é€šçŸ¥æ‰€æœ‰ WebSocket å®¢æˆ·ç«¯"""
        message = {'type': msg_type, 'data': data.dict() if hasattr(data, 'dict') else data}
        for callback in self._ws_callbacks:
            try:
                callback(message)
            except Exception as e:
                logger.error(f"WebSocket å›è°ƒå¤±è´¥: {e}")
    
    # ========================================================================
    # è½¬æ¢å‡½æ•°
    # ========================================================================
    
    def _trade_to_response(self, trade: MemoryTrade) -> TradeResponse:
        return TradeResponse(
            tx_hash=trade.tx_hash,
            log_index=trade.log_index,
            block_number=trade.block_number,
            timestamp=trade.timestamp,
            contract=trade.contract,
            maker=trade.maker,
            taker=trade.taker,
            token_id=trade.token_id,
            side=trade.side,
            price=trade.price,
            size=trade.size,
            volume=trade.volume,
            is_wash=trade.is_wash,
            wash_type=trade.wash_type,
            wash_confidence=trade.wash_confidence,
            market_name=self.get_market_name(trade.token_id),
        )
    
    def _alert_to_response(self, alert: MemoryAlert) -> AlertResponse:
        return AlertResponse(
            alert_id=alert.alert_id,
            timestamp=alert.timestamp,
            alert_type=alert.alert_type,
            severity=alert.severity,
            tx_hash=alert.tx_hash,
            token_id=alert.token_id,
            trade_count=alert.trade_count,
            volume=alert.volume,
            confidence=alert.confidence,
            addresses=alert.addresses,
            market_name=self.get_market_name(alert.token_id) if alert.token_id else None,
        )
    
    def _health_to_response(self, health: MarketHealthData) -> MarketHealth:
        return MarketHealth(
            token_id=health.token_id,
            market_name=self.get_market_name(health.token_id),
            health_score=health.health_score,
            wash_ratio=health.wash_ratio,
            total_volume=float(health.total_volume),
            organic_volume=float(health.organic_volume),
            total_trades=health.total_trades,
            unique_traders=len(health.unique_traders),
            suspicious_count=len(health.suspicious_addresses),
        )


# ============================================================================
# å…¨å±€å®ä¾‹
# ============================================================================

_data_store: Optional[DataStore] = None


def get_data_store() -> DataStore:
    """è·å–æ•°æ®å­˜å‚¨å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _data_store
    if _data_store is None:
        _data_store = DataStore()
        _data_store.start_sync()
    return _data_store
