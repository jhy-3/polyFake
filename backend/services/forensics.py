"""
PolySleuth - å–è¯æœåŠ¡

è´Ÿè´£ï¼š
- é“¾ä¸Šæ•°æ®è·å–
- å®æ—¶åˆ·é‡æ£€æµ‹
- æµå¼ç›‘æ§
- å…¨éƒ¨å®‰å…¨åˆ†æè‡ªåŠ¨è¿è¡Œ
"""
import threading
import time
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Callable
from decimal import Decimal
import logging
import requests
from collections import defaultdict

from web3 import Web3
from web3.middleware import ExtraDataToPOAMiddleware

from ..config import (
    POLYGON_RPC_URL, CTF_EXCHANGE, NEG_RISK_EXCHANGE,
    GAMMA_API_URL, POLL_INTERVAL, BLOCKS_PER_POLL
)
from .storage import get_data_store, MemoryTrade, MemoryAlert

logger = logging.getLogger(__name__)

# äº‹ä»¶ç­¾å
ORDER_FILLED_TOPIC = Web3.keccak(text="OrderFilled(bytes32,address,address,uint256,uint256,uint256,uint256,uint256)").hex()


class ForensicsService:
    """å–è¯åˆ†ææœåŠ¡ - å®æ—¶å®‰å…¨æ£€æµ‹"""
    
    def __init__(self, rpc_url: str = POLYGON_RPC_URL):
        self.rpc_url = rpc_url
        self.w3: Optional[Web3] = None
        self.store = get_data_store()
        
        # æµå¼ç›‘æ§
        self._streaming = False
        self._stream_thread: Optional[threading.Thread] = None
        self._callbacks: List[Callable] = []
        
        # å®æ—¶åˆ†æç»Ÿè®¡ï¼ˆæ¯ç§æ£€æµ‹ç±»å‹çš„è®¡æ•°ï¼‰
        self._analysis_stats = {
            'insider': 0,           # æ–°é’±åŒ…å†…å¹•
            'high_winrate': 0,      # é«˜èƒœç‡
            'gas_anomaly': 0,       # Gaså¼‚å¸¸
            'self_trade': 0,        # è‡ªäº¤æ˜“
            'circular': 0,          # å¾ªç¯äº¤æ˜“
            'atomic': 0,            # åŸå­åˆ·é‡
            'sybil': 0,             # å¥³å·«é›†ç¾¤
            'volume_spike': 0,      # äº¤æ˜“é‡å¼‚å¸¸
        }
        self._analysis_lock = threading.Lock()
        
        # ç”¨äºé«˜çº§æ£€æµ‹çš„ç¼“å­˜
        self._recent_trades_cache = []  # æœ€è¿‘äº¤æ˜“ç¼“å­˜ï¼ˆç”¨äºæ¨¡å¼æ£€æµ‹ï¼‰
        self._wallet_first_trade = {}   # é’±åŒ…é¦–æ¬¡äº¤æ˜“æ—¶é—´
        self._wallet_trade_stats = defaultdict(lambda: {'wins': 0, 'total': 0, 'volume': 0})
        self._market_volume_bins = defaultdict(lambda: defaultdict(float))  # å¸‚åœºäº¤æ˜“é‡åˆ†ç®±
        
        # ç¼“å­˜
        self._block_timestamps: Dict[int, datetime] = {}
        self._market_map_thread: Optional[threading.Thread] = None
        self._connect_thread: Optional[threading.Thread] = None
        
        # åå°è¿æ¥èŠ‚ç‚¹ï¼ˆé¿å…é˜»å¡å¯åŠ¨ï¼‰
        self._connect_thread = threading.Thread(
            target=self._connect,
            daemon=True,
        )
        self._connect_thread.start()

        # åå°åŠ è½½å¸‚åœºæ˜ å°„ï¼ˆé¿å…é˜»å¡å¯åŠ¨ï¼‰
        self._market_map_thread = threading.Thread(
            target=self._load_market_map,
            daemon=True,
        )
        self._market_map_thread.start()
    
    def _connect(self):
        """è¿æ¥åˆ° Polygon èŠ‚ç‚¹"""
        try:
            self.w3 = Web3(Web3.HTTPProvider(self.rpc_url))
            self.w3.middleware_onion.inject(ExtraDataToPOAMiddleware, layer=0)
            
            if self.w3.is_connected():
                chain_id = self.w3.eth.chain_id
                block = self.w3.eth.block_number
                logger.info(f"âœ… å·²è¿æ¥åˆ° Polygon (Chain ID: {chain_id}, Block: {block})")
                return True
            else:
                logger.error("âŒ æ— æ³•è¿æ¥åˆ° Polygon èŠ‚ç‚¹")
                return False
        except Exception as e:
            logger.error(f"âŒ è¿æ¥å¤±è´¥: {e}")
            self.w3 = None
            return False
    
    def _load_market_map(self):
        """åŠ è½½å¸‚åœºåç§°æ˜ å°„ï¼ˆåªè·å–æ´»è·ƒå¸‚åœºï¼‰"""
        all_markets = []
        try:
            # åªè·å–æ´»è·ƒå¸‚åœº
            logger.info("ğŸ“¡ å¼€å§‹è·å–æ´»è·ƒå¸‚åœº...")
            offset = 0
            page_size = 500
            max_markets = 3000
            retry_count = 0
            max_retries = 3
            
            while offset < max_markets:
                try:
                    resp = requests.get(
                        f"{GAMMA_API_URL}/markets",
                        params={'active': 'true', 'limit': page_size, 'offset': offset, 'closed': 'false'},
                        timeout=30
                    )
                    resp.raise_for_status()
                    markets = resp.json()
                    
                    if not markets:
                        break
                    
                    all_markets.extend(markets)
                    logger.info(f"  âœ“ æ´»è·ƒå¸‚åœºç¬¬ {offset//page_size + 1} é¡µ: {len(markets)} ä¸ª")
                    
                    if len(markets) < page_size:
                        break
                    
                    offset += page_size
                    retry_count = 0
                    
                except Exception as e:
                    retry_count += 1
                    if retry_count >= max_retries:
                        logger.warning(f"è·å–æ´»è·ƒå¸‚åœºç¬¬ {offset//page_size + 1} é¡µå¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {e}")
                        break
                    logger.warning(f"è·å–æ´»è·ƒå¸‚åœºç¬¬ {offset//page_size + 1} é¡µå¤±è´¥ï¼Œé‡è¯• {retry_count}/{max_retries}: {e}")
                    import time
                    time.sleep(2)
            
            logger.info(f"âœ… æ€»å…±è·å–åˆ° {len(all_markets)} ä¸ªæ´»è·ƒå¸‚åœº")
            
            count = 0
            event_count = 0
            for market in all_markets:
                question = market.get('question', '')
                # é‡è¦ï¼šPolymarket URL éœ€è¦ event slugï¼Œä¸æ˜¯ market slug
                # event slug åœ¨ events[0].slug ä¸­ï¼Œmarket.slug æ˜¯ market slugï¼ˆæ— æ³•æ‰“å¼€é¡µé¢ï¼‰
                events = market.get('events', [])
                event_slug = events[0].get('slug', '') if events else ''
                slug = event_slug or market.get('slug', '')  # ä¼˜å…ˆä½¿ç”¨ event slug
                condition_id = market.get('conditionId', '')
                
                # ä» clobTokenIds è·å–ï¼ˆæ–°æ ¼å¼ï¼‰
                clob_token_ids = market.get('clobTokenIds', '')
                if clob_token_ids:
                    import json
                    try:
                        token_ids = json.loads(clob_token_ids) if isinstance(clob_token_ids, str) else clob_token_ids
                    except Exception as e:
                        logger.warning(f"è§£æ clobTokenIds å¤±è´¥: {e}")
                        token_ids = []
                    
                    outcomes_str = market.get('outcomes', '')
                    try:
                        outcomes = json.loads(outcomes_str) if isinstance(outcomes_str, str) else outcomes_str
                    except:
                        outcomes = ['YES', 'NO']
                    
                    # è·å– event IDï¼ˆPolymarket URL ä½¿ç”¨ï¼‰
                    market_id = (
                        market.get('eventId', '')
                        or market.get('event_id', '')
                        or market.get('id', '')
                        or market.get('marketId', '')
                    )
                    
                    # ä¸ºæ¯ä¸ª token å­˜å‚¨ä¿¡æ¯
                    for idx, tid in enumerate(token_ids):
                        if tid:
                            outcome = outcomes[idx] if idx < len(outcomes) else f'Outcome {idx}'
                            self.store.cache_market(str(tid), {
                                'question': question,
                                'slug': slug,
                                'outcome': outcome,
                                'condition_id': condition_id,
                                'market_id': market_id,
                            })
                            count += 1
                    
                    # å»ºç«‹ slug åˆ° token_ids å’Œ condition_id çš„æ˜ å°„
                    if slug:
                        self.store.cache_market_event(slug, {
                            'question': question,
                            'slug': slug,
                            'condition_id': condition_id,
                            'token_ids': [str(tid) for tid in token_ids if tid],
                            'market_id': market_id,
                        })
                        event_count += 1
                
                # ä» tokens è·å–ï¼ˆæ—§æ ¼å¼ï¼Œä½œä¸ºåå¤‡ï¼‰
                tokens = market.get('tokens', [])
                token_ids_old = []
                market_id = (
                    market.get('eventId', '')
                    or market.get('event_id', '')
                    or market.get('id', '')
                    or market.get('marketId', '')
                )
                for token in tokens:
                    tid = str(token.get('token_id', ''))
                    outcome = token.get('outcome', '').upper()
                    if tid:
                        self.store.cache_market(tid, {
                            'question': question,
                            'slug': slug,
                            'outcome': outcome,
                            'condition_id': condition_id,
                            'market_id': market_id,
                        })
                        token_ids_old.append(tid)
                        count += 1
                
                # ä¸ºæ—§æ ¼å¼ä¹Ÿå»ºç«‹ event æ˜ å°„
                if slug and token_ids_old:
                    self.store.cache_market_event(slug, {
                        'question': question,
                        'slug': slug,
                        'condition_id': condition_id,
                        'token_ids': token_ids_old,
                        'market_id': market_id,
                    })
                    event_count += 1
            
            logger.info(f"âœ… åŠ è½½ {count} ä¸ªå¸‚åœºæ˜ å°„ï¼Œ{event_count} ä¸ªäº‹ä»¶æ˜ å°„")
        except Exception as e:
            logger.warning(f"åŠ è½½å¸‚åœºæ˜ å°„å¤±è´¥: {e}")
    
    def is_connected(self) -> bool:
        """æ£€æŸ¥è¿æ¥çŠ¶æ€"""
        return self.w3 is not None and self.w3.is_connected()
    
    def get_current_block(self) -> int:
        """è·å–å½“å‰åŒºå—"""
        if self.w3:
            return self.w3.eth.block_number
        return 0
    
    def get_analysis_stats(self) -> Dict[str, int]:
        """è·å–å®æ—¶åˆ†æç»Ÿè®¡"""
        with self._analysis_lock:
            return dict(self._analysis_stats)
    
    def _increment_analysis_stat(self, stat_type: str, count: int = 1):
        """å¢åŠ åˆ†æç»Ÿè®¡è®¡æ•°"""
        with self._analysis_lock:
            if stat_type in self._analysis_stats:
                self._analysis_stats[stat_type] += count
    
    # ========================================================================
    # å®æ—¶å®‰å…¨åˆ†æï¼ˆå¯¹æ¯ç¬”äº¤æ˜“è‡ªåŠ¨è¿è¡Œï¼‰
    # ========================================================================
    
    def analyze_trade_realtime(self, trade: MemoryTrade) -> Dict[str, any]:
        """
        å®æ—¶åˆ†æå•ç¬”äº¤æ˜“ï¼Œè¿è¡Œå…¨éƒ¨å®‰å…¨æ£€æµ‹
        
        è¿”å›æ£€æµ‹ç»“æœå­—å…¸
        """
        results = {
            'is_suspicious': False,
            'detections': [],
            'analysis_types': []
        }
        
        # 1. è‡ªäº¤æ˜“æ£€æµ‹ (maker == taker)
        if trade.maker.lower() == trade.taker.lower():
            results['is_suspicious'] = True
            results['detections'].append('SELF_TRADE')
            results['analysis_types'].append('self_trade')
            self._increment_analysis_stat('self_trade')
            
            # æ ‡è®°å¹¶åˆ›å»ºè­¦æŠ¥
            self.store.mark_wash_trade(
                trade.tx_hash, trade.log_index,
                "SELF_TRADE", 1.0
            )
            alert = MemoryAlert(
                alert_id=f"SELF_{trade.tx_hash[:16]}_{trade.log_index}",
                timestamp=trade.timestamp,
                alert_type="SELF_TRADE",
                severity="HIGH",
                tx_hash=trade.tx_hash,
                token_id=trade.token_id,
                trade_count=1,
                volume=trade.volume,
                confidence=1.0,
                addresses=[trade.maker],
            )
            self.store.add_alert(alert)
        
        # 2. æ–°é’±åŒ…å†…å¹•æ£€æµ‹
        insider_result = self._check_new_wallet_insider(trade)
        if insider_result:
            results['is_suspicious'] = True
            results['detections'].append('NEW_WALLET_INSIDER')
            results['analysis_types'].append('insider')
            self._increment_analysis_stat('insider')
            
            alert = MemoryAlert(
                alert_id=f"INSIDER_{trade.tx_hash[:16]}",
                timestamp=trade.timestamp,
                alert_type="NEW_WALLET_INSIDER",
                severity="HIGH",
                tx_hash=trade.tx_hash,
                token_id=trade.token_id,
                trade_count=1,
                volume=trade.volume,
                confidence=insider_result['confidence'],
                addresses=[insider_result['wallet']],
            )
            self.store.add_alert(alert)
        
        # 3. å¾ªç¯äº¤æ˜“æ£€æµ‹ï¼ˆä¸æœ€è¿‘äº¤æ˜“å¯¹æ¯”ï¼‰
        circular_result = self._check_circular_trade(trade)
        if circular_result:
            results['is_suspicious'] = True
            results['detections'].append('CIRCULAR_TRADE')
            results['analysis_types'].append('circular')
            self._increment_analysis_stat('circular')
            
            self.store.mark_wash_trade(
                trade.tx_hash, trade.log_index,
                "CIRCULAR", 0.85
            )
            alert = MemoryAlert(
                alert_id=f"CIRC_{trade.tx_hash[:8]}",
                timestamp=trade.timestamp,
                alert_type="CIRCULAR_TRADE",
                severity="MEDIUM",
                tx_hash=trade.tx_hash,
                token_id=trade.token_id,
                trade_count=2,
                volume=trade.volume + circular_result.get('paired_volume', 0),
                confidence=0.85,
                addresses=[trade.maker, trade.taker],
            )
            self.store.add_alert(alert)
        
        # 4. åŸå­åˆ·é‡æ£€æµ‹ï¼ˆåŒåŒºå—ä¹°å–å¯¹å†²ï¼‰
        atomic_result = self._check_atomic_wash(trade)
        if atomic_result:
            results['is_suspicious'] = True
            results['detections'].append('ATOMIC_WASH')
            results['analysis_types'].append('atomic')
            self._increment_analysis_stat('atomic')
            
            self.store.mark_wash_trade(
                trade.tx_hash, trade.log_index,
                "ATOMIC_WASH", 0.9
            )
            alert = MemoryAlert(
                alert_id=f"ATOMIC_{trade.tx_hash[:16]}",
                timestamp=trade.timestamp,
                alert_type="ATOMIC_WASH",
                severity="HIGH",
                tx_hash=trade.tx_hash,
                token_id=trade.token_id,
                trade_count=1,
                volume=trade.volume,
                confidence=0.9,
                addresses=[trade.maker],
            )
            self.store.add_alert(alert)
        
        # 5. å¥³å·«é›†ç¾¤æ£€æµ‹ï¼ˆçŸ­æ—¶é—´å†…å¤šé’±åŒ…åŒå‘æŠ•æ³¨ï¼‰
        sybil_result = self._check_sybil_cluster(trade)
        if sybil_result:
            results['is_suspicious'] = True
            results['detections'].append('SYBIL_CLUSTER')
            results['analysis_types'].append('sybil')
            self._increment_analysis_stat('sybil')
            
            alert = MemoryAlert(
                alert_id=f"SYBIL_{trade.token_id[:8]}_{int(trade.timestamp.timestamp())}",
                timestamp=trade.timestamp,
                alert_type="SYBIL_CLUSTER",
                severity="MEDIUM",
                tx_hash=trade.tx_hash,
                token_id=trade.token_id,
                trade_count=sybil_result['cluster_size'],
                volume=sybil_result['total_volume'],
                confidence=sybil_result['confidence'],
                addresses=sybil_result['addresses'],
            )
            self.store.add_alert(alert)
        
        # 6. äº¤æ˜“é‡å¼‚å¸¸æ£€æµ‹
        spike_result = self._check_volume_spike(trade)
        if spike_result:
            results['is_suspicious'] = True
            results['detections'].append('VOLUME_SPIKE')
            results['analysis_types'].append('volume_spike')
            self._increment_analysis_stat('volume_spike')
            
            alert = MemoryAlert(
                alert_id=f"SPIKE_{trade.token_id[:8]}_{int(trade.timestamp.timestamp())}",
                timestamp=trade.timestamp,
                alert_type="VOLUME_SPIKE",
                severity="MEDIUM",
                tx_hash=trade.tx_hash,
                token_id=trade.token_id,
                trade_count=1,
                volume=spike_result['spike_volume'],
                confidence=spike_result['confidence'],
                addresses=[],
            )
            self.store.add_alert(alert)
        
        # æ›´æ–°ç¼“å­˜
        self._update_trade_caches(trade)
        
        return results
    
    def _check_new_wallet_insider(self, trade: MemoryTrade) -> Optional[Dict]:
        """
        æ£€æµ‹æ–°é’±åŒ…å†…å¹•äº¤æ˜“
        
        çœŸæ­£å¯ç–‘çš„ç‰¹å¾ï¼š
        1. é’±åŒ…åœ¨ç³»ç»Ÿä¸­é¦–æ¬¡å‡ºç°å°±è¿›è¡Œè¶…å¤§é¢äº¤æ˜“ï¼ˆ>$1000ï¼‰
        2. é’±åŒ…è´¦é¾„å¾ˆçŸ­ï¼ˆ<24hï¼‰å°±è¿›è¡Œå¤§é¢äº¤æ˜“ï¼ˆ>$2000ï¼‰
        
        æ³¨æ„ï¼šéœ€è¦è¶³å¤Ÿçš„ç¼“å­˜æ•°æ®æ‰èƒ½å‡†ç¡®åˆ¤æ–­ï¼Œå¦åˆ™æ‰€æœ‰é’±åŒ…éƒ½ä¼šè¢«è¯¯åˆ¤ä¸º"æ–°é’±åŒ…"
        """
        # éœ€è¦è‡³å°‘ç´¯ç§¯100ç¬”äº¤æ˜“æ‰å¼€å§‹æ£€æµ‹ï¼Œé¿å…å¯åŠ¨æ—¶è¯¯æŠ¥
        if len(self._recent_trades_cache) < 100:
            # ä»ç„¶è®°å½•é’±åŒ…é¦–æ¬¡äº¤æ˜“æ—¶é—´ï¼Œä½†ä¸è§¦å‘è­¦æŠ¥
            for wallet in [trade.maker.lower(), trade.taker.lower()]:
                if wallet not in self._wallet_first_trade:
                    self._wallet_first_trade[wallet] = trade.timestamp
            return None
        
        for wallet in [trade.maker.lower(), trade.taker.lower()]:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°é’±åŒ…
            if wallet not in self._wallet_first_trade:
                self._wallet_first_trade[wallet] = trade.timestamp
                
                # æ–°é’±åŒ…è¶…å¤§é¢äº¤æ˜“ï¼ˆ>$1000ï¼‰æ‰è§¦å‘
                if trade.volume > 1000:
                    return {
                        'wallet': wallet,
                        'confidence': min(0.9, 0.5 + trade.volume / 5000),
                        'volume': trade.volume
                    }
            else:
                # æ£€æŸ¥è´¦é¾„
                first_trade_time = self._wallet_first_trade[wallet]
                age_hours = (trade.timestamp - first_trade_time).total_seconds() / 3600
                
                # è´¦é¾„<24h ä¸” è¶…å¤§é¢äº¤æ˜“ï¼ˆ>$2000ï¼‰
                if age_hours < 24 and trade.volume > 2000:
                    return {
                        'wallet': wallet,
                        'confidence': min(0.85, 0.4 + trade.volume / 10000),
                        'volume': trade.volume,
                        'age_hours': age_hours
                    }
        
        return None
    
    def _check_circular_trade(self, trade: MemoryTrade) -> Optional[Dict]:
        """æ£€æµ‹å¾ªç¯äº¤æ˜“ï¼ˆAâ†’B, Bâ†’A æ¨¡å¼ï¼‰"""
        # æŸ¥æ‰¾æœ€è¿‘60ç§’å†…çš„åå‘äº¤æ˜“
        cutoff_time = trade.timestamp - timedelta(seconds=60)
        
        for recent in reversed(self._recent_trades_cache[-500:]):
            if recent.timestamp < cutoff_time:
                break
            
            # æ£€æµ‹ Aâ†’B, Bâ†’A æ¨¡å¼
            if (recent.token_id == trade.token_id and
                recent.taker.lower() == trade.maker.lower() and
                recent.maker.lower() == trade.taker.lower()):
                
                # æ ‡è®°é…å¯¹äº¤æ˜“
                self.store.mark_wash_trade(
                    recent.tx_hash, recent.log_index,
                    "CIRCULAR", 0.85
                )
                
                return {
                    'paired_tx': recent.tx_hash,
                    'paired_volume': recent.volume
                }
        
        return None
    
    def _check_atomic_wash(self, trade: MemoryTrade) -> Optional[Dict]:
        """æ£€æµ‹åŸå­åˆ·é‡ï¼ˆåŒåŒºå—ä¹°å–å¯¹å†²ï¼‰"""
        # æŸ¥æ‰¾åŒåŒºå—ã€åŒåœ°å€çš„åå‘äº¤æ˜“
        for recent in reversed(self._recent_trades_cache[-100:]):
            if recent.block_number != trade.block_number:
                continue
            
            if (recent.maker.lower() == trade.maker.lower() and
                recent.token_id == trade.token_id and
                recent.side != trade.side):
                
                # æ£€æŸ¥äº¤æ˜“é‡æ˜¯å¦ç›¸è¿‘
                volume_ratio = min(recent.volume, trade.volume) / max(recent.volume, trade.volume) if max(recent.volume, trade.volume) > 0 else 0
                
                if volume_ratio > 0.8:
                    return {
                        'paired_tx': recent.tx_hash,
                        'volume_ratio': volume_ratio
                    }
        
        return None
    
    def _check_sybil_cluster(self, trade: MemoryTrade) -> Optional[Dict]:
        """
        æ£€æµ‹å¥³å·«é›†ç¾¤ï¼ˆçŸ­æ—¶é—´å†…å¤šé’±åŒ…ååŒæŠ•æ³¨ï¼‰
        
        çœŸæ­£çš„å¥³å·«æ”»å‡»ç‰¹å¾ï¼š
        1. æçŸ­æ—¶é—´çª—å£å†…ï¼ˆ5ç§’å†…ï¼‰å¤§é‡ä¸åŒåœ°å€åŒå‘æ“ä½œ
        2. äº¤æ˜“é‡‘é¢é«˜åº¦ç›¸ä¼¼ï¼ˆå¯èƒ½æ˜¯è„šæœ¬æ‰¹é‡æ‰§è¡Œï¼‰
        3. å‚ä¸åœ°å€æ•°é‡å¼‚å¸¸å¤šï¼ˆ>=5ä¸ªä¸åŒåœ°å€ï¼‰
        4. æ€»äº¤æ˜“é‡è¾ƒå¤§ï¼ˆæ’é™¤å°é¢æ­£å¸¸äº¤æ˜“ï¼‰
        """
        # æŸ¥æ‰¾5ç§’çª—å£å†…åŒå¸‚åœºåŒæ–¹å‘çš„äº¤æ˜“ï¼ˆæ›´ä¸¥æ ¼çš„æ—¶é—´çª—å£ï¼‰
        cutoff_time = trade.timestamp - timedelta(seconds=5)
        cluster_trades = [trade]
        
        for recent in reversed(self._recent_trades_cache[-200:]):
            if recent.timestamp < cutoff_time:
                break
            
            if (recent.token_id == trade.token_id and
                recent.side == trade.side and
                recent.maker.lower() != trade.maker.lower()):
                
                # æ£€æŸ¥äº¤æ˜“è§„æ¨¡æ˜¯å¦é«˜åº¦ç›¸ä¼¼ï¼ˆå¯èƒ½æ˜¯è„šæœ¬æ‰¹é‡ä¸‹å•ï¼‰
                if trade.volume > 0 and recent.volume > 0:
                    size_ratio = min(recent.volume, trade.volume) / max(recent.volume, trade.volume)
                    # æ›´ä¸¥æ ¼ï¼šäº¤æ˜“é‡‘é¢ç›¸ä¼¼åº¦éœ€è¦>85%
                    if size_ratio > 0.85:
                        cluster_trades.append(recent)
        
        # å¿…é¡»æ»¡è¶³æ›´ä¸¥æ ¼çš„æ¡ä»¶
        addresses = list(set(t.maker.lower() for t in cluster_trades))
        total_volume = sum(t.volume for t in cluster_trades)
        
        # æ¡ä»¶ï¼šè‡³å°‘5ä¸ªä¸åŒåœ°å€ ä¸” æ€»äº¤æ˜“é‡>$50ï¼ˆæ’é™¤å°é¢æ­£å¸¸äº¤æ˜“ï¼‰
        if len(addresses) >= 5 and total_volume >= 50:
            return {
                'cluster_size': len(addresses),
                'addresses': addresses[:10],
                'total_volume': total_volume,
                'confidence': min(0.9, 0.5 + len(addresses) * 0.08)
            }
        
        return None
    
    def _check_volume_spike(self, trade: MemoryTrade) -> Optional[Dict]:
        """æ£€æµ‹äº¤æ˜“é‡å¼‚å¸¸"""
        # 5åˆ†é’Ÿåˆ†ç®±
        bin_key = trade.timestamp.strftime('%Y%m%d%H') + str(trade.timestamp.minute // 5)
        market_id = trade.token_id
        
        # æ›´æ–°å½“å‰åˆ†ç®±
        self._market_volume_bins[market_id][bin_key] += trade.volume
        current_volume = self._market_volume_bins[market_id][bin_key]
        
        # è®¡ç®—è¿‡å»1å°æ—¶çš„å¹³å‡å€¼
        volumes = list(self._market_volume_bins[market_id].values())
        if len(volumes) >= 6:  # è‡³å°‘æœ‰30åˆ†é’Ÿæ•°æ®
            baseline = sum(volumes[:-1]) / (len(volumes) - 1)
            
            if baseline > 0 and current_volume > baseline * 10:
                return {
                    'spike_volume': current_volume,
                    'baseline_volume': baseline,
                    'spike_ratio': current_volume / baseline,
                    'confidence': min(0.85, 0.5 + (current_volume / baseline - 10) * 0.02)
                }
        
        return None
    
    def _update_trade_caches(self, trade: MemoryTrade):
        """æ›´æ–°äº¤æ˜“ç¼“å­˜"""
        self._recent_trades_cache.append(trade)
        
        # ä¿æŒç¼“å­˜å¤§å°
        if len(self._recent_trades_cache) > 2000:
            self._recent_trades_cache = self._recent_trades_cache[-1500:]
        
        # æ¸…ç†è¿‡æœŸçš„ volume binsï¼ˆä¿ç•™æœ€è¿‘2å°æ—¶ï¼‰
        cutoff = (trade.timestamp - timedelta(hours=2)).strftime('%Y%m%d%H')
        for market_id in list(self._market_volume_bins.keys()):
            bins = self._market_volume_bins[market_id]
            for bin_key in list(bins.keys()):
                if bin_key < cutoff:
                    del bins[bin_key]
    
    # ========================================================================
    # æ•°æ®è·å–
    # ========================================================================
    
    def fetch_recent_trades(self, num_blocks: int = 100) -> int:
        """è·å–æœ€è¿‘äº¤æ˜“å¹¶è‡ªåŠ¨åˆ†æ"""
        if not self.is_connected():
            logger.error("èŠ‚ç‚¹æœªè¿æ¥")
            return 0
        
        try:
            current_block = self.w3.eth.block_number
            from_block = current_block - num_blocks
            
            logger.info(f"ğŸ“¡ è·å–åŒºå— {from_block} åˆ° {current_block} çš„äº¤æ˜“...")
            
            # è·å–ä¸¤ä¸ªäº¤æ˜“æ‰€çš„æ—¥å¿—
            trades_count = 0
            suspicious_count = 0
            
            for exchange_addr in [CTF_EXCHANGE, NEG_RISK_EXCHANGE]:
                logs = self.w3.eth.get_logs({
                    'fromBlock': from_block,
                    'toBlock': current_block,
                    'address': Web3.to_checksum_address(exchange_addr),
                    'topics': [ORDER_FILLED_TOPIC],
                })
                
                for log in logs:
                    trade = self._decode_order_filled(log, exchange_addr)
                    if trade:
                        self.store.add_trade(trade, notify=False)
                        trades_count += 1
                        
                        # å®æ—¶åˆ†ææ¯ç¬”äº¤æ˜“
                        analysis = self.analyze_trade_realtime(trade)
                        if analysis['is_suspicious']:
                            suspicious_count += 1
            
            logger.info(f"âœ… è·å– {trades_count} ç¬”äº¤æ˜“ï¼Œæ£€æµ‹åˆ° {suspicious_count} ç¬”å¯ç–‘")
            
            # é€šçŸ¥å‰ç«¯æ›´æ–°åˆ†æç»Ÿè®¡
            self._notify_analysis_stats()
            
            return trades_count
        
        except Exception as e:
            logger.error(f"è·å–äº¤æ˜“å¤±è´¥: {e}")
            return 0
    
    def _notify_analysis_stats(self):
        """é€šçŸ¥å‰ç«¯æ›´æ–°åˆ†æç»Ÿè®¡"""
        stats = self.get_analysis_stats()
        
        # è®¡ç®—å¥åº·è¯„åˆ†
        total_suspicious = sum(stats.values())
        total_trades = len(self._recent_trades_cache)
        
        if total_trades > 0:
            suspicious_ratio = total_suspicious / total_trades
            health_score = max(0, min(100, 100 - suspicious_ratio * 200))
        else:
            health_score = 100
        
        risk_level = 'LOW'
        if health_score < 40:
            risk_level = 'CRITICAL'
        elif health_score < 60:
            risk_level = 'HIGH'
        elif health_score < 80:
            risk_level = 'MEDIUM'
        
        self.store._notify_ws('analysis_stats', {
            'stats': stats,
            'health_score': health_score,
            'risk_level': risk_level,
            'total_evidence': total_suspicious,
        })
    
    def _decode_order_filled(self, log, exchange: str) -> Optional[MemoryTrade]:
        """è§£ç  OrderFilled äº‹ä»¶"""
        try:
            topics = log['topics']
            data = log['data']
            
            # è§£ç  topics
            order_hash = topics[1].hex() if len(topics) > 1 else ""
            maker = "0x" + topics[2].hex()[-40:] if len(topics) > 2 else ""
            taker = "0x" + topics[3].hex()[-40:] if len(topics) > 3 else ""
            
            # è§£ç  data (5 ä¸ª uint256: makerAssetId, takerAssetId, makerAmountFilled, takerAmountFilled, fee)
            if isinstance(data, str):
                data = bytes.fromhex(data[2:])
            
            values = []
            for i in range(5):
                offset = i * 32
                if offset + 32 <= len(data):
                    values.append(int.from_bytes(data[offset:offset+32], 'big'))
                else:
                    values.append(0)
            
            maker_asset_id, taker_asset_id, maker_amount, taker_amount, fee = values
            
            # è®¡ç®—äº¤æ˜“æ–¹å‘å’Œä»·æ ¼
            if maker_asset_id == 0:
                side = "BUY"
                token_id = str(taker_asset_id)
                usdc_amount = maker_amount
                token_amount = taker_amount
            else:
                side = "SELL"
                token_id = str(maker_asset_id)
                usdc_amount = taker_amount
                token_amount = maker_amount
            
            price = usdc_amount / token_amount if token_amount > 0 else 0
            size = token_amount / 1e6
            volume = size * price
            
            # è·å–åŒºå—æ—¶é—´
            block_number = log['blockNumber']
            timestamp = self._get_block_timestamp(block_number)
            
            return MemoryTrade(
                tx_hash=log['transactionHash'].hex(),
                log_index=log['logIndex'],
                block_number=block_number,
                timestamp=timestamp,
                contract=exchange,
                order_hash=order_hash,
                maker=maker,
                taker=taker,
                token_id=token_id,
                side=side,
                price=price,
                size=size,
                volume=volume,
                fee=fee,
            )
        
        except Exception as e:
            logger.debug(f"è§£ç å¤±è´¥: {e}")
            return None
    
    def _get_block_timestamp(self, block_number: int) -> datetime:
        """è·å–åŒºå—æ—¶é—´"""
        if block_number in self._block_timestamps:
            return self._block_timestamps[block_number]
        
        now = datetime.now()
        try:
            current_block = self.w3.eth.block_number
            seconds_ago = (current_block - block_number) * 2
            self._block_timestamps[block_number] = now - timedelta(seconds=seconds_ago)
        except:
            self._block_timestamps[block_number] = now
        
        return self._block_timestamps[block_number]
    
    # ========================================================================
    # åˆ·é‡æ£€æµ‹
    # ========================================================================
    
    def detect_self_trades(self):
        """æ£€æµ‹è‡ªæˆäº¤"""
        trades = self.store.get_trades(limit=10000, is_wash=False)
        detected = 0
        
        for trade in trades:
            if trade.maker.lower() == trade.taker.lower():
                self.store.mark_wash_trade(
                    trade.tx_hash, trade.log_index,
                    "SELF_TRADE", 1.0
                )
                
                # æ·»åŠ è­¦æŠ¥
                alert = MemoryAlert(
                    alert_id=f"SELF_{trade.tx_hash[:16]}_{trade.log_index}",
                    timestamp=trade.timestamp,
                    alert_type="SELF_TRADE",
                    severity="HIGH",
                    tx_hash=trade.tx_hash,
                    token_id=trade.token_id,
                    trade_count=1,
                    volume=trade.volume,
                    confidence=1.0,
                    addresses=[trade.maker],
                )
                self.store.add_alert(alert)
                detected += 1
        
        if detected:
            logger.info(f"ğŸ”´ æ£€æµ‹åˆ° {detected} ç¬”è‡ªæˆäº¤")
    
    def detect_circular_trades(self, time_window: int = 60):
        """æ£€æµ‹ç¯å½¢äº¤æ˜“"""
        trades = self.store.get_trades(limit=10000, is_wash=False)
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_trades = sorted(trades, key=lambda t: t.timestamp)
        detected = 0
        
        for i, trade in enumerate(sorted_trades):
            if trade.is_wash:
                continue
            
            for j in range(i + 1, len(sorted_trades)):
                later = sorted_trades[j]
                
                time_diff = (later.timestamp - trade.timestamp).total_seconds()
                if time_diff > time_window:
                    break
                
                # æ£€æµ‹ Aâ†’B, Bâ†’A æ¨¡å¼
                if (trade.taker.lower() == later.maker.lower() and
                    trade.maker.lower() == later.taker.lower() and
                    trade.token_id == later.token_id):
                    
                    self.store.mark_wash_trade(
                        trade.tx_hash, trade.log_index,
                        "CIRCULAR", 0.85
                    )
                    self.store.mark_wash_trade(
                        later.tx_hash, later.log_index,
                        "CIRCULAR", 0.85
                    )
                    
                    alert = MemoryAlert(
                        alert_id=f"CIRC_{trade.tx_hash[:8]}_{later.tx_hash[:8]}",
                        timestamp=trade.timestamp,
                        alert_type="CIRCULAR_TRADE",
                        severity="MEDIUM",
                        tx_hash=trade.tx_hash,
                        token_id=trade.token_id,
                        trade_count=2,
                        volume=trade.volume + later.volume,
                        confidence=0.85,
                        addresses=[trade.maker, trade.taker],
                    )
                    self.store.add_alert(alert)
                    detected += 1
        
        if detected:
            logger.info(f"ğŸŸ  æ£€æµ‹åˆ° {detected} ç»„ç¯å½¢äº¤æ˜“")
    
    # ========================================================================
    # æµå¼ç›‘æ§
    # ========================================================================
    
    def start_streaming(self, poll_interval: float = POLL_INTERVAL,
                       blocks_per_poll: int = BLOCKS_PER_POLL):
        """å¯åŠ¨æµå¼ç›‘æ§"""
        if self._streaming:
            return
        
        self._streaming = True
        self._stream_thread = threading.Thread(
            target=self._stream_loop,
            args=(poll_interval, blocks_per_poll),
            daemon=True
        )
        self._stream_thread.start()
        logger.info(f"ğŸ“º æµå¼ç›‘æ§å·²å¯åŠ¨ (é—´éš”: {poll_interval}s, æ¯æ¬¡: {blocks_per_poll} åŒºå—)")
    
    def stop_streaming(self):
        """åœæ­¢æµå¼ç›‘æ§"""
        self._streaming = False
        if self._stream_thread:
            self._stream_thread.join(timeout=5)
        logger.info("ğŸ“º æµå¼ç›‘æ§å·²åœæ­¢")
    
    def is_streaming(self) -> bool:
        """æ˜¯å¦æ­£åœ¨æµå¼ç›‘æ§"""
        return self._streaming
    
    def _stream_loop(self, poll_interval: float, blocks_per_poll: int):
        """æµå¼ç›‘æ§å¾ªç¯ - å®æ—¶è·å–å¹¶åˆ†ææ¯ç¬”äº¤æ˜“"""
        last_block = self.get_current_block()
        
        while self._streaming:
            time.sleep(poll_interval)
            
            try:
                current_block = self.get_current_block()
                
                if current_block > last_block:
                    new_blocks = min(current_block - last_block, blocks_per_poll)
                    from_block = current_block - new_blocks
                    
                    # è·å–æ–°äº¤æ˜“å¹¶å®æ—¶åˆ†æ
                    for exchange_addr in [CTF_EXCHANGE, NEG_RISK_EXCHANGE]:
                        try:
                            logs = self.w3.eth.get_logs({
                                'fromBlock': from_block,
                                'toBlock': current_block,
                                'address': Web3.to_checksum_address(exchange_addr),
                                'topics': [ORDER_FILLED_TOPIC],
                            })
                            
                            for log in logs:
                                trade = self._decode_order_filled(log, exchange_addr)
                                if trade:
                                    # å…ˆæ·»åŠ äº¤æ˜“
                                    self.store.add_trade(trade, notify=True)
                                    
                                    # å®æ—¶åˆ†ææ¯ç¬”äº¤æ˜“
                                    analysis = self.analyze_trade_realtime(trade)
                                    
                                    # å¦‚æœå‘ç°å¯ç–‘ï¼Œé€šçŸ¥å‰ç«¯
                                    if analysis['is_suspicious']:
                                        self.store._notify_ws('suspicious_trade', {
                                            'trade': {
                                                'tx_hash': trade.tx_hash,
                                                'maker': trade.maker,
                                                'taker': trade.taker,
                                                'volume': trade.volume,
                                                'token_id': trade.token_id,
                                            },
                                            'detections': analysis['detections'],
                                            'analysis_types': analysis['analysis_types'],
                                        })
                        except Exception as e:
                            logger.debug(f"è·å–æ—¥å¿—å¤±è´¥: {e}")
                    
                    last_block = current_block
                    
                    # é€šçŸ¥åˆ†æç»Ÿè®¡æ›´æ–°
                    self._notify_analysis_stats()
                    
                    # é€šçŸ¥ç»Ÿè®¡æ›´æ–°
                    stats = self.store.get_stats()
                    stats.is_streaming = True
                    self.store._notify_ws('stats', stats)
            
            except Exception as e:
                logger.error(f"æµå¼ç›‘æ§é”™è¯¯: {e}")


# ============================================================================
# å…¨å±€å®ä¾‹
# ============================================================================

_forensics_service: Optional[ForensicsService] = None


def get_forensics_service() -> ForensicsService:
    """è·å–å–è¯æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _forensics_service
    if _forensics_service is None:
        _forensics_service = ForensicsService()
    return _forensics_service
